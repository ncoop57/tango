# AUTOGENERATED! DO NOT EDIT! File to edit: dev/01_features.ipynb (unless otherwise specified).

__all__ = ['Extractor', 'SIFTExtractor', 'CNNExtractor', 'imgs', '#extractor', 'extractor', 'features', 'gen_vcodebook',
           'get_df', 'get_bovw', 'calc_tf_idf']

# Cell
class Extractor(ABC):

    def __init__(self, extractor):
        self.extractor = extractor
        super().__init__()

    @abstractmethod
    def extract(self, img):
        pass

# Cell
class SIFTExtractor(Extractor):

    def extract(self, img):
        _, features = self.extractor.detectAndCompute(img, None)
        return features

class CNNExtractor(Extractor):

    def extract(self, img):
        return self.extractor.getFeatures(img)

# Cell
imgs = get_rand_imgs(video_paths[0], 30_000, n = 100)

# Cell
#learn, linear_output_layer = cnn.trainPetsModel()
#extractor = CNNExtractor(cnn.createExtractor(None, None, 'resnet50', False))
extractor = CNNExtractor(cnn.createLayeredExtractor())

# Cell
#CNN features
# features = extractor.extract(imgs[0]);
# print(features.shape)

# # SIFT features
# features = extractor.extract(imgs[1])
# print(features.shape)

#Layered implementation
features = extractor.extract(imgs[0])

# Cell
def gen_vcodebook(imgs, extractor, vwords = 10_000):
    """
        Constructs a visual codebook based on the given images.
        You can change vwords to increase the vocabulary of the codebook.
    """
    features_list = []
    for img in imgs:
        features = extractor.extract(img)
        features_list.extend(features)

    codebook = KMeans(n_clusters = vwords)
    codebook.fit(features_list)

    return codebook

# Cell
def get_df(imgs, extractor, codebook):
    """Generates the document frequency for the visual words"""
    hist = None
    for img in imgs:
        features = extractor.extract(img);
        vw = codebook.predict(features)
        if hist is not None:
            hist += np.clip(np.histogram(vw, bins = vwords)[0], 0, 1)
        else:
            hist = np.clip(np.histogram(vw, bins = vwords)[0], 0, 1)

    return hist

# Cell
def get_bovw(vid_path, extractor, codebook):
    """Generates the bag of visual words (bovw) for an entire video."""
    vid = cv2.VideoCapture(str(vid_path))

    # checks whether frames were extracted
    success = 1
    bovw = np.array([])
    for i in progress_bar(range(100)):
        # vid object calls read
        # function extract frames
        success, img = vid.read()
        if success:
            features = extractor.extract(img)
            vw = codebook.predict(features)
            bovw = np.concatenate((bovw, vw))

    hist = np.histogram(bovw, bins = vwords)[0]
    return hist, bovw

# Cell
def calc_tf_idf(tfs, dfs):
    tf_idf = np.array([])
    for tf, df in zip(tfs, dfs):
        tf = tf / np.sum(tfs)
        idf = np.log(len(tfs) / (df + 1))
        tf_idf = np.append(tf_idf, tf * idf)

    return tf_idf
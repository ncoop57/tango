# AUTOGENERATED! DO NOT EDIT! File to edit: dev/01_features.ipynb (unless otherwise specified).

__all__ = ['Extractor', 'SIFTExtractor', 'CNNExtractor', 'gen_vcodebook', 'get_df', 'get_bovw', 'calc_tf_idf']

# Cell
import cv2
import ffmpeg

import torch

import numpy as np

from abc import ABC, abstractmethod

from fastprogress.fastprogress import progress_bar

# tango
from .prep import *

from .cnn import *

from pathlib import Path

from matplotlib import pyplot as plt

from nbdev.showdoc import *

from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity

# Cell
class Extractor(ABC):

    def __init__(self, extractor):
        self.extractor = extractor
        super().__init__()

    @abstractmethod
    def extract(self, img):
        pass

# Cell

class SIFTExtractor(Extractor):

    '''Exposed SIFTExtractor class used for retrieving features.'''

    def extract(self, img):
        '''Given an image, extract features using SIFT. Returns the feature vector.'''
        _, features = self.extractor.detectAndCompute(img, None)
        return features

class CNNExtractor(Extractor):

    '''Exposed CNNExtractor class used for retrieving features.'''

    def extract(self, img):
        '''Given an image, extract features from the layers of a CNN. Returns the feature vector.'''

        return self.extractor.getFeatures(img)

show_doc(CNNExtractor.extract)
show_doc(SIFTExtractor.extract)

# Cell
def gen_vcodebook(imgs, extractor, vwords = 10_000):
    """
        Constructs a visual codebook based on the given images.
        You can change vwords to increase the vocabulary of the codebook.
    """
    features_list = []
    for img in imgs:
        features = extractor.extract(img)
        features_list.extend(features)

    codebook = KMeans(n_clusters = vwords)
    codebook.fit(features_list)

    return codebook

# Cell
def get_df(imgs, extractor, codebook):
    """Generates the document frequency for the visual words"""
    hist = None
    for img in imgs:
        features = extractor.extract(img);
        vw = codebook.predict(features)
        if hist is not None:
            hist += np.clip(np.histogram(vw, bins = vwords)[0], 0, 1)
        else:
            hist = np.clip(np.histogram(vw, bins = vwords)[0], 0, 1)

    return hist

# Cell
def get_bovw(vid_path, extractor, codebook):
    """Generates the bag of visual words (bovw) for an entire video."""
    vid = cv2.VideoCapture(str(vid_path))

    # checks whether frames were extracted
    success = 1
    bovw = np.array([])
    for i in progress_bar(range(100)):
        # vid object calls read
        # function extract frames
        success, img = vid.read()
        if success:
            features = extractor.extract(img)
            vw = codebook.predict(features)
            bovw = np.concatenate((bovw, vw))

    hist = np.histogram(bovw, bins = vwords)[0]
    return hist, bovw

# Cell
def calc_tf_idf(tfs, dfs):
    tf_idf = np.array([])
    for tf, df in zip(tfs, dfs):
        tf = tf / np.sum(tfs)
        idf = np.log(len(tfs) / (df + 1))
        tf_idf = np.append(tf_idf, tf * idf)

    return tf_idf
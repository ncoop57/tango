{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.16.0)\n",
      "Looking in links: https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu102/torch-1.7.0.dev20200702-cp36-cp36m-linux_x86_64.whl (893.2 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu102/torchvision-0.8.0.dev20200701-cp36-cp36m-linux_x86_64.whl (5.9 MB)\n",
      "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.0)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.1.0)\n",
      "\u001b[31mERROR: torchvision 0.8.0.dev20200701 has requirement torch==1.7.0.dev20200701, but you'll have torch 1.7.0.dev20200702 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.3.1\n",
      "    Uninstalling torch-1.3.1:\n",
      "      Successfully uninstalled torch-1.3.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.4.2\n",
      "    Uninstalling torchvision-0.4.2:\n",
      "      Successfully uninstalled torchvision-0.4.2\n",
      "Successfully installed torch-1.7.0.dev20200702 torchvision-0.8.0.dev20200701\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy\n",
    "! pip install --pre -U torch torchvision -f https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-0.8.4-py3-none-any.whl (304 kB)\n",
      "\u001b[K     |████████████████████████████████| 304 kB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyYAML>=5.1\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "\u001b[K     |████████████████████████████████| 269 kB 13.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm>=4.41.0\n",
      "  Downloading tqdm-4.47.0-py2.py3-none-any.whl (66 kB)\n",
      "\u001b[K     |████████████████████████████████| 66 kB 12.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.7.0.dev20200702)\n",
      "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.18.5)\n",
      "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (0.18.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (2.24.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.6.0.post3)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.30.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (3.12.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.18.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (3.2.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (47.3.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.15.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (0.4.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (0.9.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/lib/python3/dist-packages (from tensorboard>=1.14->pytorch-lightning) (0.30.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (2.6)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (1.25.9)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (4.1.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning) (3.1.0)\n",
      "Building wheels for collected packages: PyYAML\n",
      "  Building wheel for PyYAML (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=45919 sha256=6420b08d2a2f9d7f97a06d8a95662cd3c32468e455f2c683d62f723e12f5f9ef\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/9d/ad/2ee53cf262cba1ffd8afe1487eef788ea3f260b7e6232a80fc\n",
      "Successfully built PyYAML\n",
      "Installing collected packages: PyYAML, tqdm, pytorch-lightning\n",
      "Successfully installed PyYAML-5.3.1 pytorch-lightning-0.8.4 tqdm-4.47.0\n"
     ]
    }
   ],
   "source": [
    "! pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "class SimCLRDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        \"\"\"Initialize a wrapper of a generic image classification dataset for SimCLR training.\n",
    "\n",
    "        Args:\n",
    "            dataset (torch.utils.data.Dataset): an image PyTorch dataset - when iterating over it\n",
    "                it should return something of the form (image) or (image, label).\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        dataset_item = self.dataset[index]\n",
    "        if type(dataset_item) is tuple:\n",
    "            image = dataset_item[0]\n",
    "        else:\n",
    "            image = dataset_item\n",
    "        return image, image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    @staticmethod\n",
    "    def mixup(x, alpha=0.4):\n",
    "        batch_size = x.size()[0] // 2\n",
    "        if alpha > 0:\n",
    "            lam = np.random.beta(alpha, alpha, batch_size)\n",
    "            lam = np.concatenate(\n",
    "                [lam[:, None], 1 - lam[:, None]], 1\n",
    "            ).max(1)[:, None, None, None]\n",
    "            lam = torch.from_numpy(lam).float()\n",
    "            if torch.cuda.is_available():\n",
    "                lam = lam.cuda()\n",
    "        else:\n",
    "            lam = 1.\n",
    "        # This is SimCLR specific - we want to use the same mixing for the augmented pairs\n",
    "        lam = torch.cat([lam, lam])\n",
    "        index = torch.randperm(batch_size)\n",
    "        # This is SimCLR specific - we want to use the same permutation on the augmented pairs\n",
    "        index = torch.cat([index, batch_size + index])\n",
    "        if torch.cuda.is_available():\n",
    "            index = index.cuda()\n",
    "        mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "\n",
    "        return mixed_x, lam\n",
    "\n",
    "\n",
    "def imagenet_normalize_transform():\n",
    "    return transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "def get_train_transforms(size=224, color_jitter_prob=0.8, grayscale_prob=0.2):\n",
    "    color_jitter = transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=(size, size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomApply([color_jitter], p=color_jitter_prob),\n",
    "        transforms.RandomGrayscale(p=grayscale_prob),\n",
    "        transforms.ToTensor(),\n",
    "        imagenet_normalize_transform()\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_val_transforms(size=224):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(size=(size, size)),\n",
    "        transforms.ToTensor(),\n",
    "        imagenet_normalize_transform()\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class NTXEntCriterion(nn.Module):\n",
    "    \"\"\"Normalized, temperature-scaled cross-entropy criterion, as suggested in the SimCLR paper.\n",
    "\n",
    "    Parameters:\n",
    "        temperature (float, optional): temperature to scale the confidences. Defaults to 0.5.\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "    similarity = nn.CosineSimilarity(dim=2)\n",
    "\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super(NTXEntCriterion, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.batch_size = None\n",
    "        self.mask = None\n",
    "\n",
    "    def mask_correlated_samples(self, batch_size):\n",
    "        \"\"\"Masks examples in a batch and it's augmented pair for computing the valid summands for\n",
    "            the criterion.\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): batch size of the individual batch (not including it's augmented pair)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: a mask (tensor of 0s and 1s), where 1s indicates a pair of examples in a\n",
    "                batch that will contribute to the overall batch loss\n",
    "        \"\"\"\n",
    "        mask = torch.ones((batch_size * 2, batch_size * 2), dtype=bool)\n",
    "        mask = mask.fill_diagonal_(0)\n",
    "        for i in range(batch_size):\n",
    "            mask[i, batch_size + i] = 0\n",
    "            mask[batch_size + i, i] = 0\n",
    "        return mask\n",
    "\n",
    "    def compute_similarities(self, z_i, z_j, temperature):\n",
    "        \"\"\"Computes the similarities between two projections `z_i` and `z_j`, scaling based on\n",
    "            `temperature`.\n",
    "\n",
    "        Args:\n",
    "            z_i (torch.Tensor): projection of a batch\n",
    "            z_j (torch.Tensor): projection of the augmented pair for the batch\n",
    "            temperature (float): temperature to scale the similarity by\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: tensor of similarities for the positive and negative pairs\n",
    "        \"\"\"\n",
    "        batch_size = len(z_i)\n",
    "        mask = self.mask_correlated_samples(batch_size)\n",
    "\n",
    "        p1 = torch.cat((z_i, z_j), dim=0)\n",
    "        sim = self.similarity(p1.unsqueeze(1), p1.unsqueeze(0)) / temperature\n",
    "\n",
    "        sim_i_j = torch.diag(sim, batch_size)\n",
    "        sim_j_i = torch.diag(sim, -batch_size)\n",
    "\n",
    "        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(\n",
    "            batch_size * 2, 1\n",
    "        )\n",
    "        negative_samples = sim[mask].reshape(batch_size * 2, -1)\n",
    "\n",
    "        logits = torch.cat((positive_samples, negative_samples), dim=1)\n",
    "        return logits\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"Computes the loss for a batch and its augmented pair.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): tensor of a batch and it's augmented pair, concatenated\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: loss for the given batch\n",
    "        \"\"\"\n",
    "        double_batch_size = len(z)\n",
    "        batch_size = double_batch_size // 2\n",
    "        z_i, z_j = z[:double_batch_size // 2], z[double_batch_size // 2:]\n",
    "        if self.batch_size is None or batch_size != self.batch_size:\n",
    "            self.batch_size = batch_size\n",
    "            self.mask = None\n",
    "\n",
    "        if self.mask is None:\n",
    "            self.mask = self.mask_correlated_samples(self.batch_size)\n",
    "\n",
    "        logits = self.compute_similarities(z_i, z_j, self.temperature)\n",
    "        labels = torch.zeros(self.batch_size * 2).long()\n",
    "        logits, labels = logits.to(z.device), labels.to(z.device)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        loss /= 2 * self.batch_size\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "class SimCLRModel(LightningModule):\n",
    "    \"\"\"SimCLR training network for a generic torchvision model (restricted to `allowed_models`). \"\"\"\n",
    "\n",
    "    allowed_models = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152']\n",
    "    allowed_datasets = ['CIFAR10', 'CIFAR100', 'STL10', 'SVHN']\n",
    "\n",
    "    def __init__(\n",
    "        self, model_name='resnet18', pretrained=True, projection_dim=64, temperature=0.5,\n",
    "        batch_size=128, image_size=224, save_hparams=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        layers = list(getattr(torchvision.models, model_name)(pretrained=pretrained).children())\n",
    "        self.model = nn.Sequential(*layers[:-1])\n",
    "        self.projection_head = nn.Linear(layers[-1].in_features, projection_dim)\n",
    "        self.loss = NTXEntCriterion(temperature=temperature)\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.prepare_data()\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(\"Forwarding\")\n",
    "        out = self.model(x)\n",
    "        out = out.view(x.size(0), -1)\n",
    "        out = self.projection_head(out)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "#         print(\"Training step\")\n",
    "        projections = self(batch)\n",
    "        loss = self.loss(projections)\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        self.logger.scalar('loss', loss)\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "#         print(\"Finished Epoch\")\n",
    "        loss_mean = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        return {'train_loss': loss_mean}\n",
    "\n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "# #         print(\"Validation step\")\n",
    "#         projections = self(batch)\n",
    "#         loss = self.loss(projections)\n",
    "#         tensorboard_logs = {'val_loss': loss}\n",
    "#         return {'loss': loss, 'log': tensorboard_logs}\n",
    "\n",
    "#     def validation_epoch_end(self, outputs):\n",
    "# #         print(\"Finished Epoch\")\n",
    "#         val_loss_mean = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "#         return {'val_loss': val_loss_mean}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam([\n",
    "            {'params': self.model.parameters(), 'lr': 0.00001},\n",
    "            {'params': self.projection_head.parameters(), 'lr': 0.001}\n",
    "        ])\n",
    "\n",
    "    def prepare_data(self):\n",
    "#         print(\"Getting Data\")\n",
    "        train_transforms, val_transforms = (\n",
    "            get_train_transforms(size=self.image_size),\n",
    "            get_val_transforms(size=self.image_size)\n",
    "        )\n",
    "        train_dataset = torchvision.datasets.ImageFolder(\n",
    "            '/tf/data/combined', transform = train_transforms)\n",
    "        self.train_dataset = SimCLRDataset(train_dataset)\n",
    "#         val_dataset = torchvision.datasets.ImageFolder(\n",
    "#             '/tf/data/combined', transform = val_transforms)\n",
    "#         self.val_dataset = SimCLRDataset(val_dataset)\n",
    "#         print(\"Finished getting data\")\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "#         print(\"Collating data\")\n",
    "        return torch.cat([torch.stack([b[0] for b in batch]), torch.stack([b[1] for b in batch])])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "#         print(\"Grabbing dataloader\")\n",
    "        return DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, num_workers=64, shuffle=True,\n",
    "            collate_fn=self.collate_fn\n",
    "        )\n",
    "\n",
    "#     def val_dataloader(self):\n",
    "# #         print(\"Grabbing dataloader\")\n",
    "#         return DataLoader(\n",
    "#             self.val_dataset, batch_size=self.batch_size, num_workers=64, shuffle=False,\n",
    "#             collate_fn=self.collate_fn\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = SimCLRModel(\n",
    "    model_name = 'resnet50',\n",
    "    pretrained = True,\n",
    "    batch_size = 1792,\n",
    "    image_size = 224\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimCLRModel.load_from_checkpoint(checkpoint_path='/tf/data/models/simclr/checkpointepoch=98.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/tf/data/models/simclr/simclr-epoch98.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: Checkpoint directory /tf/data/models/simclr/ exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e2fa7c6642d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Trainer' is not defined"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath = '/tf/data/models/simclr/', prefix = \"checkpoint\",\n",
    "    monitor = \"val_loss\", mode = \"min\", save_top_k = 3\n",
    ")\n",
    "\n",
    "train_params = dict(\n",
    "#     accumulate_grad_batches = 1, # hparams.gradient_accumulation_steps,\n",
    "    gpus = 3,\n",
    "    max_epochs = 5, # hparams.num_train_epochs,\n",
    "    early_stop_callback = False,\n",
    "#     gradient_clip_val = 3, # hparams.max_grad_norm,\n",
    "#     checkpoint_callback = checkpoint_callback,\n",
    "    num_nodes = 1,\n",
    "    prepare_data_per_node = False,\n",
    "    distributed_backend = 'ddp',\n",
    "#     precision = 16\n",
    "#     num_workers = 0\n",
    "#     callbacks=[LoggingCallback()],\n",
    ")\n",
    "\n",
    "trainer = Trainer(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-31a2232f4f6903b0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-31a2232f4f6903b0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --bind_all --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# trainer = Trainer.from_argparse_args(args)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

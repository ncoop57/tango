{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#default_exp cli"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CLI\n",
    "\n",
    "\n",
    "> This module contains all the code for defining Tango's CLI"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# export\n",
    "import logging\n",
    "import io\n",
    "import pickle\n",
    "import pprint\n",
    "import random\n",
    "import requests\n",
    "import subprocess\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fastcore.script import call_parse, Param\n",
    "from pathlib import Path\n",
    "from two_to_tango.prep import *\n",
    "from two_to_tango.features import *\n",
    "from two_to_tango.eval import *\n",
    "from two_to_tango.model import *\n",
    "from two_to_tango.approach import *\n",
    "from two_to_tango.combo import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# export\n",
    "URLs = {\n",
    "    \"tango_reproduction_package\": \"https://zenodo.org/record/4453765/files/tango_reproduction_package.zip\",\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# export\n",
    "# @call_parse\n",
    "def _download(\n",
    "    out_path\n",
    "):\n",
    "    \"\"\"Function for downloading all data and results related to this tool's paper\"\"\"\n",
    "    out_path = Path(out_path)\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    logging.info(f\"Downloading and extracting datasets and models to {str(out_path)}.\")\n",
    "    r = requests.get(URLs[\"tango_reproduction_package\"])\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    z.extractall(out_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# export\n",
    "@call_parse\n",
    "def download(\n",
    "    out_path: Param(\"The output path to save and unzip all files.\", str)\n",
    "):\n",
    "    _download(out_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "download(\"/tf/main/data\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# export\n",
    "# all hyperparameters used\n",
    "VWORDS = [1_000, 5_000, 10_000]\n",
    "N_IMGS = 15_000\n",
    "N_FRAMES_TO_KEEP = [1, 5]\n",
    "FPS = 30\n",
    "\n",
    "# Fix naming issue and number of models reported...\n",
    "BEST_DL_MODELS= [\n",
    "    \"SIFT-10000vw-1ftk-bovw_weighted_lcs\",\n",
    "    \"SimCLR-1000vw-5ftk-bovw\", \"SimCLR-5000vw-5ftk-bovw_lcs\",\n",
    "    \"SimCLR-5000vw-5ftk-bovw_weighted_lcs\", \"SimCLR-1000vw-5ftk-bovw_weighted_lcs\"\n",
    "]\n",
    "BEST_IR_MODELS = [\n",
    "    \"ocr+ir-1ftk-all_text\", \"ocr+ir-5ftk-all_text\",\n",
    "    \"ocr+ir-5ftk-unique_frames\", \"ocr+ir-5ftk-unique_words\"\n",
    "]\n",
    "\n",
    "BEST_MODEL_CONFIGS = {\n",
    "    \"SimCLR\": \"SimCLR-1000vw-5ftk-bovw\",\n",
    "    \"SIFT\": \"SIFT-10000vw-1ftk-bovw_weighted_lcs\",\n",
    "    \"OCR+IR\": \"ocr+ir-5ftk-all_text\"\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# export\n",
    "def _generate_vis_results(vid_ds, out_path, art_path, vis_model):\n",
    "    if vis_model == \"SimCLR\":\n",
    "        simclr = SimCLRModel.load_from_checkpoint(\n",
    "            checkpoint_path = str(\n",
    "                art_path/\"models\"/\"SimCLR\"/\"checkpointepoch=98.ckpt\"\n",
    "            )\n",
    "        ).eval()\n",
    "        model = SimCLRExtractor(simclr)\n",
    "        sim_func = simclr_frame_sim\n",
    "    else:\n",
    "        model = SIFTExtractor(cv2.xfeatures2d.SIFT_create(nfeatures = 10))\n",
    "        sim_func = sift_frame_sim\n",
    "\n",
    "    logging.info(f\"Computing rankings and calculating metrics for {vis_model} visual model.\")\n",
    "    for vw in tqdm(VWORDS):\n",
    "        for ftk in tqdm(N_FRAMES_TO_KEEP):\n",
    "            evaluation_metrics = {}\n",
    "            cb_path = art_path/\"models\"/vis_model/f\"cookbook_{vis_model}_{vw}vw.model\"\n",
    "            codebook = pickle.load(open(cb_path, \"rb\"))\n",
    "            start = time.time()\n",
    "            vid_ds_features = gen_extracted_features(vid_ds, model, FPS, ftk)\n",
    "            end = time.time()\n",
    "            feature_gen_time = end - start\n",
    "            \n",
    "            df, bovw_vid_ds_sims = gen_bovw_similarity(\n",
    "                vid_ds, vid_ds_features, model, codebook, vw, ftk\n",
    "            )\n",
    "            lcs_vid_ds_sims = gen_lcs_similarity(\n",
    "                vid_ds, vid_ds_features, sim_func, model, codebook, df, vw, ftk\n",
    "            )\n",
    "            rankings = approach(\n",
    "                vid_ds, vid_ds_features, bovw_vid_ds_sims, lcs_vid_ds_sims, model, sim_func,\n",
    "                codebook, df, vw, fps = FPS, ftk = ftk,\n",
    "            )\n",
    "\n",
    "            for k, v in rankings.items():\n",
    "                evaluation_metrics[k] = evaluate(rankings[k])\n",
    "\n",
    "            id_name = f\"user_{N_IMGS}n_{vw}vw_{FPS}fps_{ftk}ftk\"\n",
    "            results_path = out_path/\"results\"/vis_model\n",
    "            results_path.mkdir(parents=True, exist_ok=True)\n",
    "            logging.info(f\"Saving rankings and metrics to {str(results_path)}.\")\n",
    "            with open(results_path/f\"rankings_{id_name}.pkl\", \"wb\") as f:\n",
    "                pickle.dump(rankings, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            with open(results_path/f\"evaluation_metrics_{id_name}.pkl\", 'wb') as f:\n",
    "                pickle.dump(evaluation_metrics, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# VWORDS = [1_000]\n",
    "# N_IMGS = 15_000\n",
    "# N_FRAMES_TO_KEEP = [1]\n",
    "FPS = 30\n",
    "\n",
    "out_path = Path(\"/tf/main/data/output\")\n",
    "art_path = Path(\"/tf/main/data/tango_reproduction_package/artifacts\")\n",
    "vis_model = \"SimCLR\"\n",
    "\n",
    "# vid_ds = VideoDataset.from_path(\n",
    "#     art_path/\"videos\", fr = FPS\n",
    "# ).label_from_paths()\n",
    "\n",
    "# _generate_vis_results(vid_ds, out_path, art_path, vis_model)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# export\n",
    "def _generate_txt_results(vid_ds, out_path, art_path, vis_model):\n",
    "    logging.info(\"Computing rankings and calculating metrics for textual model.\")\n",
    "    csv_file_path = art_path/\"user_assignment.csv\"\n",
    "    settings_path = out_path/\"evaluation_settings\"\n",
    "    settings_path.mkdir(parents=True, exist_ok=True)\n",
    "    video_data = read_video_data(csv_file_path)\n",
    "    generate_setting2(video_data, settings_path)\n",
    "    convert_results_format(out_path/\"results\", settings_path, out_path, [vis_model])\n",
    "\n",
    "    # Check if files already exist and skip if they do because it takes a long time\n",
    "    txt_out_path = out_path/\"extracted_text\"\n",
    "    for ftk in N_FRAMES_TO_KEEP:\n",
    "        if not (txt_out_path/f\"text_{ftk}\").exists():\n",
    "            get_all_texts(vid_ds, txt_out_path, fps = ftk)\n",
    "\n",
    "    txt_path = art_path/\"models\"/\"OCR+IR\"\n",
    "    subprocess.check_output(\n",
    "        [\"sh\", \"build_run.sh\", str(txt_out_path), str(settings_path)],\n",
    "        cwd=str(txt_path),\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "N_FRAMES_TO_KEEP = [1, 5]\n",
    "_generate_txt_results(None, out_path, art_path, vis_model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:root:Computing rankings and calculating metrics for textual model.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['lcs', 'weighted_lcs', 'bovw', 'bovw_lcs', 'bovw_weighted_lcs'])\n",
      "Running config:  {'model': 'SimCLR', 'vwords': '1000vw', 'fps': '30fps', 'ftk': '1ftk', 'technique': 'weighted_lcs'}\n",
      "Running setting setting2\n",
      "dict_keys(['lcs', 'weighted_lcs', 'bovw', 'bovw_lcs', 'bovw_weighted_lcs'])\n",
      "Running config:  {'model': 'SimCLR', 'vwords': '1000vw', 'fps': '30fps', 'ftk': '1ftk', 'technique': 'bovw'}\n",
      "Running setting setting2\n",
      "dict_keys(['lcs', 'weighted_lcs', 'bovw', 'bovw_lcs', 'bovw_weighted_lcs'])\n",
      "Running config:  {'model': 'SimCLR', 'vwords': '1000vw', 'fps': '30fps', 'ftk': '1ftk', 'technique': 'lcs'}\n",
      "Running setting setting2\n",
      "dict_keys(['lcs', 'weighted_lcs', 'bovw', 'bovw_lcs', 'bovw_weighted_lcs'])\n",
      "Running config:  {'model': 'SimCLR', 'vwords': '1000vw', 'fps': '30fps', 'ftk': '1ftk', 'technique': 'bovw_lcs'}\n",
      "Running setting setting2\n",
      "dict_keys(['lcs', 'weighted_lcs', 'bovw', 'bovw_lcs', 'bovw_weighted_lcs'])\n",
      "Running config:  {'model': 'SimCLR', 'vwords': '1000vw', 'fps': '30fps', 'ftk': '1ftk', 'technique': 'bovw_weighted_lcs'}\n",
      "Running setting setting2\n",
      "dict_keys(['lcs', 'weighted_lcs', 'bovw', 'bovw_lcs', 'bovw_weighted_lcs'])\n",
      "Running config:  {'model': 'SimCLR', 'vwords': '1000vw', 'fps': '30fps', 'ftk': '5ftk', 'technique': 'weighted_lcs'}\n",
      "Running setting setting2\n",
      "dict_keys(['lcs', 'weighted_lcs', 'bovw', 'bovw_lcs', 'bovw_weighted_lcs'])\n",
      "Running config:  {'model': 'SimCLR', 'vwords': '1000vw', 'fps': '30fps', 'ftk': '5ftk', 'technique': 'bovw'}\n",
      "Running setting setting2\n",
      "dict_keys(['lcs', 'weighted_lcs', 'bovw', 'bovw_lcs', 'bovw_weighted_lcs'])\n",
      "Running config:  {'model': 'SimCLR', 'vwords': '1000vw', 'fps': '30fps', 'ftk': '5ftk', 'technique': 'lcs'}\n",
      "Running setting setting2\n",
      "dict_keys(['lcs', 'weighted_lcs', 'bovw', 'bovw_lcs', 'bovw_weighted_lcs'])\n",
      "Running config:  {'model': 'SimCLR', 'vwords': '1000vw', 'fps': '30fps', 'ftk': '5ftk', 'technique': 'bovw_lcs'}\n",
      "Running setting setting2\n",
      "dict_keys(['lcs', 'weighted_lcs', 'bovw', 'bovw_lcs', 'bovw_weighted_lcs'])\n",
      "Running config:  {'model': 'SimCLR', 'vwords': '1000vw', 'fps': '30fps', 'ftk': '5ftk', 'technique': 'bovw_weighted_lcs'}\n",
      "Running setting setting2\n",
      "Writing results and rankings\n",
      "done\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "out_path = Path(\"/tf/main/data/output\")\n",
    "\n",
    "combo_out_path = out_path/\"combined\"\n",
    "dl_ranking_path = out_path/\"user_rankings_weighted_all\"/\"all_rankings.csv\"\n",
    "txt_path = art_path/\"models\"/\"OCR+IR\"\n",
    "ir_rankings_path = txt_path/\"tango_txt_rankings\"/\"all_rankings.json\"\n",
    "settings_path = out_path/\"evaluation_settings\"\n",
    "\n",
    "tango_combined(combo_out_path, dl_ranking_path, ir_rankings_path, settings_path, BEST_DL_MODELS, BEST_IR_MODELS)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tf/main/data/tango_reproduction_package/artifacts/models/OCR+IR/tango_txt_rankings/all_rankings.json'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-53e994fd6274>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msettings_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"evaluation_settings\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtango_combined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombo_out_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_ranking_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir_rankings_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBEST_DL_MODELS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBEST_IR_MODELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~tf/main/two_to_tango/combo.py\u001b[0m in \u001b[0;36mtango_combined\u001b[0;34m(out_path, dl_rankings_path, ir_rankings_path, settings_path, dl_models, ir_models)\u001b[0m\n\u001b[1;32m    208\u001b[0m                                                                     rec['technique'],))\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0mir_rankings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mir_rankings_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     ir_rankings_by_config = group_dict(ir_rankings, lambda rec: (rec['model'], rec['fps'],\n\u001b[1;32m    212\u001b[0m                                                                     rec['technique'],))\n",
      "\u001b[0;32m~tf/main/two_to_tango/utils.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tf/main/data/tango_reproduction_package/artifacts/models/OCR+IR/tango_txt_rankings/all_rankings.json'"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# export\n",
    "def _get_single_model_performance(pkl_path, technique):\n",
    "    evals = pickle.load(open(fname, 'rb'))\n",
    "    mRRs = []\n",
    "    mAPs = []\n",
    "    mean_Rs = []\n",
    "    for app in evals[technique]:\n",
    "        mRRs.append(evals[technique][app][\"App mRR\"])\n",
    "        mAPs.append(evals[technique][app][\"App mAP\"])\n",
    "        mean_Rs.append(evals[technique][app][\"App mean rank\"])\n",
    "    \n",
    "    return np.mean(mRRs), np.mean(mAPs), np.mean(mean_Rs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# export\n",
    "def _print_performance(model, mRR, mAP, mean_R):\n",
    "    print(\n",
    "        f\"\"\"\\\n",
    "        Model: {model}\n",
    "        Overall mRR: {mRR}\n",
    "        Overall mAP: {mAP}\n",
    "        Overall Mean Rank: {mean_R}\n",
    "        \"\"\"\n",
    "    )\n",
    "def _output_performance(out_path, dl_model_config, ir_model_config):\n",
    "    all_results = pd.read_csv(\n",
    "        out_path/\"combined\"/\"tango_comb_results\"/\"all_results.csv\", sep=\";\"\n",
    "    )\n",
    "    # Print the comb model results\n",
    "    comb_results = all_results[\n",
    "        all_results[\"model_config\"] == f\"({dl_model_config},{ir_model_config})\"\n",
    "    ][all_results[\"weight\"] == \"0.2-0\"]\n",
    "    _print_performance(\n",
    "        f\"{dl_model_config},{ir_model_config},weight=0.2-0\", np.mean(comb_results['recip_rank'].values),\n",
    "        np.mean(comb_results['avg_precision'].values), np.mean(comb_results['first_rank'].values)\n",
    "    )\n",
    "\n",
    "    # Print the vis model results\n",
    "    vis_singl_results = all_results[\n",
    "        all_results[\"model_config\"] == f\"({dl_model_config},{ir_model_config})\"\n",
    "    ][all_results[\"weight\"] == \"0.0\"]\n",
    "    _print_performance(\n",
    "        f\"{dl_model_config}\", np.mean(vis_singl_results['recip_rank'].values),\n",
    "        np.mean(vis_singl_results['avg_precision'].values), np.mean(vis_singl_results['first_rank'].values)\n",
    "    )\n",
    "    # Print the txt model results\n",
    "    ir_singl_results = all_results[\n",
    "        all_results[\"model_config\"] == f\"({dl_model_config},{ir_model_config})\"\n",
    "    ][all_results[\"weight\"] == \"1.0\"]\n",
    "    _print_performance(\n",
    "        f\"{ir_model_config}\", np.mean(ir_singl_results['recip_rank'].values),\n",
    "        np.mean(ir_singl_results['avg_precision'].values), np.mean(ir_singl_results['first_rank'].values)\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "vis_model = \"SimCLR\"\n",
    "out_path = Path(\"/tf/main/data/output\")\n",
    "_output_performance(out_path, BEST_MODEL_CONFIGS[vis_model], BEST_MODEL_CONFIGS[\"OCR+IR\"])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        Model: SimCLR-1000vw-5ftk-bovw,ocr+ir-5ftk-all_text,weight=0.2-0\n",
      "        Overall mRR: 0.7521122972820503\n",
      "        Overall mAP: 0.6843871569103048\n",
      "        Overall Mean Rank: 1.9419753086419753\n",
      "        \n",
      "        Model: SimCLR-1000vw-5ftk-bovw\n",
      "        Overall mRR: 0.708187709862351\n",
      "        Overall mAP: 0.6392624653390201\n",
      "        Overall Mean Rank: 2.105794790005316\n",
      "        \n",
      "        Model: ocr+ir-5ftk-all_text\n",
      "        Overall mRR: 0.725243535246192\n",
      "        Overall mAP: 0.6499718806108282\n",
      "        Overall Mean Rank: 2.0563230605738574\n",
      "        \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# export\n",
    "@call_parse\n",
    "def reproduce(\n",
    "    down_path: Param(\"The directory where all the files will be downloaded and extracted to.\", str),\n",
    "    out_path: Param(\"The output path to place all results in.\", str),\n",
    "    vis_model: Param(\"The type of visual model. Can be either SimCLR or SIFT, taking ~6 hours or >2 weeks, respectively, for all apps on our machine with 755G of RAM and 72 CPUs.\", str)\n",
    "):\n",
    "    \"\"\"Function for reproducing all results related to this tool's paper\"\"\"\n",
    "    random.seed(42)\n",
    "    _download(down_path)\n",
    "    down_path = Path(down_path)\n",
    "    out_path = Path(out_path)\n",
    "    art_path = down_path/\"tango_reproduction_package\"/\"artifacts\"\n",
    "\n",
    "    logging.info(\"Loading videos.\")\n",
    "    vid_ds = VideoDataset.from_path(\n",
    "        art_path/\"videos\", fr = None\n",
    "    ).label_from_paths()\n",
    "\n",
    "    _generate_vis_results(vid_ds, out_path, art_path, vis_model)\n",
    "    _generate_txt_results(vid_ds, out_path, art_path, vis_model)\n",
    "\n",
    "    combo_out_path = out_path/\"combined\"\n",
    "    dl_ranking_path = out_path/\"user_rankings_weighted_all\"/\"all_rankings.csv\"\n",
    "    txt_path = art_path/\"models\"/\"OCR+IR\"\n",
    "    ir_rankings_path = txt_path/\"tango_txt_rankings\"/\"all_rankings.json\"\n",
    "    settings_path = out_path/\"evaluation_settings\"\n",
    "\n",
    "    tango_combined(combo_out_path, dl_ranking_path, ir_rankings_path, settings_path, BEST_DL_MODELS, BEST_IR_MODELS)\n",
    "    _output_performance(out_path, BEST_MODEL_CONFIGS[vis_model], BEST_MODEL_CONFIGS[\"OCR+IR\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "VWORDS = [1_000]\n",
    "N_IMGS = 15_000\n",
    "N_FRAMES_TO_KEEP = [1]\n",
    "FPS = 30\n",
    "\n",
    "down_path = \"/tf/main/data\"\n",
    "out_path = \"/tf/main/data/tango_reproduction_package/outputs\"\n",
    "vis_model = \"SimCLR\"\n",
    "\n",
    "reproduce(down_path, out_path, vis_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# export\n",
    "@call_parse\n",
    "def tango(\n",
    "    q_path: Param(\"Path to the query video\", str),\n",
    "    cor_path: Param(\"Path to the corpus\", str),\n",
    "    simclr_path: Param(\"Path to the SimCLR model directory\", str)\n",
    "):\n",
    "    \"\"\"\n",
    "    Function for calculating similarity scores of a corpus of video-based bug\n",
    "    reports to a query video-based bug report. Currently only uses the top\n",
    "    performing SimCLR model from our paper\n",
    "    \"It Takes Two to TANGO: Combining Visual andTextual Information for Detecting DuplicateVideo-Based Bug Reports\".\n",
    "    \"\"\"\n",
    "    q_path = Path(q_path)\n",
    "    cor_path = Path(cor_path)\n",
    "    simclr_path = Path(simclr_path)\n",
    "    best_vw = 1_000\n",
    "    best_ftk = 5\n",
    "    \n",
    "    q_vid = Video(q_path, FPS)\n",
    "    codebook = pickle.load(open(simclr_path/f\"cookbook_SimCLR_{best_vw}vw.model\", 'rb'))\n",
    "    simclr = SimCLRModel.load_from_checkpoint(\n",
    "        checkpoint_path=str(simclr_path/\"checkpointepoch=98.ckpt\")\n",
    "    ).eval()\n",
    "    model = SimCLRExtractor(simclr)\n",
    "\n",
    "    vid_ds = VideoDataset.from_path(cor_path, fr=FPS).label_from_paths()\n",
    "    sorted_rankings = compute_sims(q_vid, vid_ds, model, codebook, best_vw, FPS, best_ftk)\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint(sorted_rankings)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corpus_path = Path(\"/tf/main/tango_reproduction_package/artifacts/cli_videos\")\n",
    "query_path = corpus_path/\"U1\"/\"APOD\"/\"CC1\"/\"APOD-CC1_fixed_30.mp4\"\n",
    "simclr_path = Path(\"/tf/main/tango_reproduction_package/artifacts/models/SimCLR\")\n",
    "tango(query_path, corpus_path, simclr_path)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converted 00_prep.ipynb.\n",
      "Converted 01_features.ipynb.\n",
      "Converted 02_eval.ipynb.\n",
      "Converted 03_model.ipynb.\n",
      "Converted 04_approach.ipynb.\n",
      "Converted 05_cli.ipynb.\n",
      "Converted 06_results.ipynb.\n",
      "Converted 07_utils.ipynb.\n",
      "Converted 08_combo.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
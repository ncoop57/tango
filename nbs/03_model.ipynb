{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "\n",
    "> This module contains all the code for extracting features and comparing features from SimCLR and SIFT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from two_to_tango.features import *\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def sift_frame_sim(features_i, features_j, codebook, df, vw):\n",
    "    vws_i = np.expand_dims(codebook.predict(features_i), axis=0)\n",
    "    bowv_i = np.expand_dims(np.histogram(vws_i, bins = range(vw + 1))[0], axis=0)\n",
    "    tf_idf_i = calc_tf_idf(bowv_i, df)\n",
    "    \n",
    "    vws_j = np.expand_dims(codebook.predict(features_j), axis=0)\n",
    "    bowv_j = np.expand_dims(np.histogram(vws_j, bins = range(vw + 1))[0], axis=0)\n",
    "    tf_idf_j = calc_tf_idf(bowv_j, df)\n",
    "    \n",
    "    sim = np.dot(tf_idf_i, tf_idf_j) / (np.linalg.norm(tf_idf_i) * np.linalg.norm(tf_idf_j))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def simclr_frame_sim(features_i, features_j, codebook, df, vw):\n",
    "    sim = cosine_similarity(features_i, features_j)[0][0]\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\"\"\"\n",
    "All code from: https://github.com/dthiagarajan/simclr_pytorch\n",
    "Only included directory for easy loading of checkpoints\n",
    "\"\"\"\n",
    "class SimCLRDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        \"\"\"Initialize a wrapper of a generic image classification dataset for SimCLR training.\n",
    "\n",
    "        Args:\n",
    "            dataset (torch.utils.data.Dataset): an image PyTorch dataset - when iterating over it\n",
    "                it should return something of the form (image) or (image, label).\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        dataset_item = self.dataset[index]\n",
    "        if type(dataset_item) is tuple:\n",
    "            image = dataset_item[0]\n",
    "        else:\n",
    "            image = dataset_item\n",
    "        return image, image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    @staticmethod\n",
    "    def mixup(x, alpha=0.4):\n",
    "        batch_size = x.size()[0] // 2\n",
    "        if alpha > 0:\n",
    "            lam = np.random.beta(alpha, alpha, batch_size)\n",
    "            lam = np.concatenate(\n",
    "                [lam[:, None], 1 - lam[:, None]], 1\n",
    "            ).max(1)[:, None, None, None]\n",
    "            lam = torch.from_numpy(lam).float()\n",
    "            if torch.cuda.is_available():\n",
    "                lam = lam.cuda()\n",
    "        else:\n",
    "            lam = 1.\n",
    "        # This is SimCLR specific - we want to use the same mixing for the augmented pairs\n",
    "        lam = torch.cat([lam, lam])\n",
    "        index = torch.randperm(batch_size)\n",
    "        # This is SimCLR specific - we want to use the same permutation on the augmented pairs\n",
    "        index = torch.cat([index, batch_size + index])\n",
    "        if torch.cuda.is_available():\n",
    "            index = index.cuda()\n",
    "        mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "\n",
    "        return mixed_x, lam\n",
    "\n",
    "\n",
    "def imagenet_normalize_transform():\n",
    "    return transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "def get_train_transforms(size=224, color_jitter_prob=0.8, grayscale_prob=0.2):\n",
    "    color_jitter = transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=(size, size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomApply([color_jitter], p=color_jitter_prob),\n",
    "        transforms.RandomGrayscale(p=grayscale_prob),\n",
    "        transforms.ToTensor(),\n",
    "        imagenet_normalize_transform()\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_val_transforms(size=224):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(size=(size, size)),\n",
    "        transforms.ToTensor(),\n",
    "        imagenet_normalize_transform()\n",
    "    ])\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class NTXEntCriterion(nn.Module):\n",
    "    \"\"\"Normalized, temperature-scaled cross-entropy criterion, as suggested in the SimCLR paper.\n",
    "\n",
    "    Parameters:\n",
    "        temperature (float, optional): temperature to scale the confidences. Defaults to 0.5.\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "    similarity = nn.CosineSimilarity(dim=2)\n",
    "\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super(NTXEntCriterion, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.batch_size = None\n",
    "        self.mask = None\n",
    "\n",
    "    def mask_correlated_samples(self, batch_size):\n",
    "        \"\"\"Masks examples in a batch and it's augmented pair for computing the valid summands for\n",
    "            the criterion.\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): batch size of the individual batch (not including it's augmented pair)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: a mask (tensor of 0s and 1s), where 1s indicates a pair of examples in a\n",
    "                batch that will contribute to the overall batch loss\n",
    "        \"\"\"\n",
    "        mask = torch.ones((batch_size * 2, batch_size * 2), dtype=bool)\n",
    "        mask = mask.fill_diagonal_(0)\n",
    "        for i in range(batch_size):\n",
    "            mask[i, batch_size + i] = 0\n",
    "            mask[batch_size + i, i] = 0\n",
    "        return mask\n",
    "\n",
    "    def compute_similarities(self, z_i, z_j, temperature):\n",
    "        \"\"\"Computes the similarities between two projections `z_i` and `z_j`, scaling based on\n",
    "            `temperature`.\n",
    "\n",
    "        Args:\n",
    "            z_i (torch.Tensor): projection of a batch\n",
    "            z_j (torch.Tensor): projection of the augmented pair for the batch\n",
    "            temperature (float): temperature to scale the similarity by\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: tensor of similarities for the positive and negative pairs\n",
    "        \"\"\"\n",
    "        batch_size = len(z_i)\n",
    "        mask = self.mask_correlated_samples(batch_size)\n",
    "\n",
    "        p1 = torch.cat((z_i, z_j), dim=0)\n",
    "        sim = self.similarity(p1.unsqueeze(1), p1.unsqueeze(0)) / temperature\n",
    "\n",
    "        sim_i_j = torch.diag(sim, batch_size)\n",
    "        sim_j_i = torch.diag(sim, -batch_size)\n",
    "\n",
    "        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(\n",
    "            batch_size * 2, 1\n",
    "        )\n",
    "        negative_samples = sim[mask].reshape(batch_size * 2, -1)\n",
    "\n",
    "        logits = torch.cat((positive_samples, negative_samples), dim=1)\n",
    "        return logits\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"Computes the loss for a batch and its augmented pair.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): tensor of a batch and it's augmented pair, concatenated\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: loss for the given batch\n",
    "        \"\"\"\n",
    "        double_batch_size = len(z)\n",
    "        batch_size = double_batch_size // 2\n",
    "        z_i, z_j = z[:double_batch_size // 2], z[double_batch_size // 2:]\n",
    "        if self.batch_size is None or batch_size != self.batch_size:\n",
    "            self.batch_size = batch_size\n",
    "            self.mask = None\n",
    "\n",
    "        if self.mask is None:\n",
    "            self.mask = self.mask_correlated_samples(self.batch_size)\n",
    "\n",
    "        logits = self.compute_similarities(z_i, z_j, self.temperature)\n",
    "        labels = torch.zeros(self.batch_size * 2).long()\n",
    "        logits, labels = logits.to(z.device), labels.to(z.device)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        loss /= 2 * self.batch_size\n",
    "        return loss\n",
    "\n",
    "class SimCLRModel(LightningModule):\n",
    "    \"\"\"SimCLR training network for a generic torchvision model (restricted to `allowed_models`). \"\"\"\n",
    "\n",
    "    allowed_models = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152']\n",
    "    allowed_datasets = ['CIFAR10', 'CIFAR100', 'STL10', 'SVHN']\n",
    "\n",
    "    def __init__(\n",
    "        self, model_name='resnet18', pretrained=True, projection_dim=64, temperature=0.5,\n",
    "        batch_size=128, image_size=224, save_hparams=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        layers = list(getattr(torchvision.models, model_name)(pretrained=pretrained).children())\n",
    "        self.model = nn.Sequential(*layers[:-1])\n",
    "        self.projection_head = nn.Linear(layers[-1].in_features, projection_dim)\n",
    "        self.loss = NTXEntCriterion(temperature=temperature)\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.prepare_data()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        out = out.view(x.size(0), -1)\n",
    "        out = self.projection_head(out)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        projections = self(batch)\n",
    "        loss = self.loss(projections)\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        self.logger.scalar('loss', loss)\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        loss_mean = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        return {'train_loss': loss_mean}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam([\n",
    "            {'params': self.model.parameters(), 'lr': 0.00001},\n",
    "            {'params': self.projection_head.parameters(), 'lr': 0.001}\n",
    "        ])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        return torch.cat([torch.stack([b[0] for b in batch]), torch.stack([b[1] for b in batch])])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, num_workers=64, shuffle=True,\n",
    "            collate_fn=self.collate_fn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_prep.ipynb.\n",
      "Converted 01_features.ipynb.\n",
      "Converted 02_eval.ipynb.\n",
      "Converted 03_model.ipynb.\n",
      "Converted 04_approach.ipynb.\n",
      "Converted 05_cli.ipynb.\n",
      "Converted 06_results.ipynb.\n",
      "Converted 07_utils.ipynb.\n",
      "Converted 08_combo.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

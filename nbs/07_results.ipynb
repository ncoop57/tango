{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "> This module contains all the code for running our experiments for Tango."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import cv2\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# tango\n",
    "from tango.prep import *\n",
    "from tango.features import *\n",
    "from tango.eval import *\n",
    "from tango.model import *\n",
    "from tango.approach import *\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "path = Path(\"/tf/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO Need to see if there are app overlaps between the RICO dataset and our validation set and user data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup\n",
    "### Description:\n",
    "* Number of Participants: 14 (10 students and 4 authors)\n",
    "* Number of Applications: 6\n",
    "* Number of Bug Reports per Application: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car_report', 'king', 'tasty']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_val = 'val'\n",
    "vid_val_ds = VideoDataset.from_path(path/\"datasets/validation_set/\", fr = fps).label_from_paths()\n",
    "vid_val_ds.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APOD', 'GROW', 'TIME', 'TOK', 'DROID', 'GNU']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_user = 'user'\n",
    "vid_user_ds = VideoDataset.from_path(path/\"datasets/user_data/\", fr = fps).label_from_paths()\n",
    "vid_user_ds.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO run evaluation both ways with all videos and then one where some bug reports don't have duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO look at original fivr paper and bovw papers for finding configuration of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup\n",
    "### Configurations:\n",
    "* Number of Visual Words: 1,000, 5,000, 10,000\n",
    "* Codebook Number of Image Samples: MAX ~50,000\n",
    "* Number of frames kept: 1, 5\n",
    "* Model + Bag of Visual Words\n",
    "* Model + Bag of Visual Words + Fuzzy LCS\n",
    "* **Potential:** Model + Bag of Visual Words + Fuzzy LCS + Weighting scheme to weight end of video more\n",
    "* **Potential:** Model + Bag of Visual Words + Fuzzy LCS + Weighting scheme to weight end of video more + V2S selection of important frames (touch indicator appears)\n",
    "\n",
    "For a total of 12 different configurations per model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIFT - M00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_00 = 'M00'\n",
    "M00 = SIFTExtractor(cv2.xfeatures2d.SIFT_create(nfeatures = 10)) # limit SIFT features to top 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCLR - M01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_01 = 'M01'\n",
    "simclr = SimCLRModel.load_from_checkpoint(checkpoint_path = str(path/'models/simclr/checkpointepoch=98.ckpt')).eval()\n",
    "M01 = SimCLRExtractor(simclr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwords = [1_000, 5_000, 10_000]\n",
    "n_imgs = 15_000 # Putting None, means use entire RICO dataset, which is equal to ...\n",
    "n_frames_to_keep = [1, 5]\n",
    "models = [(model_00, M00), (model_01, M01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_codebooks(path, models, vwords, n_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rankings(\n",
    "    path, vid_ds, ds_name, model_name, model, sim_func, vwords, n_imgs,\n",
    "     n_frames_to_keep, fps\n",
    "):\n",
    "\n",
    "    for vw in tqdm(vwords):\n",
    "        for ftk in tqdm(n_frames_to_keep):\n",
    "            rankings = {}\n",
    "            evaluation_metrics = {}\n",
    "            fname = path/f'models/codebooks/{model_name}/cookbook_{model_name}_{vw}vw.model'\n",
    "            codebook = pickle.load(open(fname, 'rb'))\n",
    "            start = time.time()\n",
    "            vid_ds_features = gen_extracted_features(vid_ds, model, fps, ftk)\n",
    "            df, bovw_vid_ds_sims = gen_bovw_similarity(vid_ds, vid_ds_features, model, codebook, vw, ftk)\n",
    "            bovw_vid_ds_sims = gen_lcs_similarity(vid_ds, vid_ds_features, sim_func, mdl, codebook, df, vw, ftk)\n",
    "            \n",
    "            \n",
    "            rankings['bovw'] = approach(\n",
    "                vid_ds, vid_ds_features, vid_ds_sims, model, sim_func,\n",
    "                codebook, df, vw, fps = fps, ftk = ftk\n",
    "            )\n",
    "            end_bovw = time.time()\n",
    "            rankings['bovw_time'] = end_bovw - start\n",
    "            evaluation_metrics['bovw'] = evaluate(\n",
    "                rankings['bovw']\n",
    "            )\n",
    "            \n",
    "            rankings['lcs'] = approach(\n",
    "                vid_ds, vid_ds_features, vid_ds_sims, model, sim_func,\n",
    "                codebook, df, vw, fps = fps, ftk = ftk, mode = 'lcs'\n",
    "            )\n",
    "            end_lcs = time.time()\n",
    "            rankings['lcs_time'] = end_lcs - start\n",
    "            evaluation_metrics['lcs'] = evaluate(\n",
    "                rankings['lcs']\n",
    "            )\n",
    "\n",
    "#             rankings['bovw_lcs'] = approach(\n",
    "#                 vid_ds, vid_ds_features, vid_ds_sims, model, sim_func,\n",
    "#                 codebook, df, vw, fps = fps, ftk = ftk, mode = 'bovw_lcs'\n",
    "#             )\n",
    "#             end_bovw_lcs = time.time()\n",
    "#             rankings['bovw_lcs_time'] = end_bovw_lcs - start\n",
    "#             evaluation_metrics['bovw_lcs'] = evaluate(\n",
    "#                 rankings['bovw_lcs']\n",
    "#             )\n",
    "            \n",
    "            id_name = f'{ds_name}_{n_imgs}n_{vw}vw_{ftk}ftk'\n",
    "            with open(path/f'results/{model_name}/rankings_{id_name}_lcs.pkl', 'wb') as f:\n",
    "                pickle.dump(rankings, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            with open(path/f'results/{model_name}/evaluation_metrics_{id_name}_lcs.pkl', 'wb') as f:\n",
    "                pickle.dump(evaluation_metrics, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rankings(\n",
    "    path, vid_ds, ds_name, model_name, model, sim_func, vwords, n_imgs,\n",
    "     n_frames_to_keep, fps\n",
    "):\n",
    "\n",
    "    for vw in tqdm(vwords):\n",
    "        for ftk in tqdm(n_frames_to_keep):\n",
    "            rankings = {}\n",
    "            evaluation_metrics = {}\n",
    "            fname = path/f'models/codebooks/{model_name}/cookbook_{model_name}_{vw}vw.model'\n",
    "            codebook = pickle.load(open(fname, 'rb'))\n",
    "            start = time.time()\n",
    "            vid_ds_features = gen_extracted_features(vid_ds, model, fps, ftk)\n",
    "            df, bovw_vid_ds_sims = gen_bovw_similarity(vid_ds, vid_ds_features, model, codebook, vw, ftk)\n",
    "            lcs_vid_ds_sims = gen_lcs_similarity(vid_ds, vid_ds_features, sim_func, mdl, codebook, df, vw, ftk)\n",
    "            \n",
    "            \n",
    "            rankings['bovw'] = approach(\n",
    "                vid_ds, vid_ds_features, vid_ds_sims, model, sim_func,\n",
    "                codebook, df, vw, fps = fps, ftk = ftk\n",
    "            )\n",
    "            end_bovw = time.time()\n",
    "            rankings['bovw_time'] = end_bovw - start\n",
    "            evaluation_metrics['bovw'] = evaluate(\n",
    "                rankings['bovw']\n",
    "            )\n",
    "            \n",
    "            rankings['lcs'] = approach(\n",
    "                vid_ds, vid_ds_features, vid_ds_sims, model, sim_func,\n",
    "                codebook, df, vw, fps = fps, ftk = ftk, mode = 'lcs'\n",
    "            )\n",
    "            end_lcs = time.time()\n",
    "            rankings['lcs_time'] = end_lcs - start\n",
    "            evaluation_metrics['lcs'] = evaluate(\n",
    "                rankings['lcs']\n",
    "            )\n",
    "\n",
    "#             rankings['bovw_lcs'] = approach(\n",
    "#                 vid_ds, vid_ds_features, vid_ds_sims, model, sim_func,\n",
    "#                 codebook, df, vw, fps = fps, ftk = ftk, mode = 'bovw_lcs'\n",
    "#             )\n",
    "#             end_bovw_lcs = time.time()\n",
    "#             rankings['bovw_lcs_time'] = end_bovw_lcs - start\n",
    "#             evaluation_metrics['bovw_lcs'] = evaluate(\n",
    "#                 rankings['bovw_lcs']\n",
    "#             )\n",
    "            \n",
    "            id_name = f'{ds_name}_{n_imgs}n_{vw}vw_{ftk}ftk'\n",
    "            with open(path/f'results/{model_name}/rankings_{id_name}_lcs.pkl', 'wb') as f:\n",
    "                pickle.dump(rankings, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            with open(path/f'results/{model_name}/evaluation_metrics_{id_name}_lcs.pkl', 'wb') as f:\n",
    "                pickle.dump(evaluation_metrics, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vid_val_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-63617a843410>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m generate_rankings(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_val_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msift_frame_sim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_imgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mn_frames_to_keep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vid_val_ds' is not defined"
     ]
    }
   ],
   "source": [
    "generate_rankings(\n",
    "    path, vid_val_ds, ds_val, model_00, M00, sift_frame_sim, vwords, n_imgs,\n",
    "    n_frames_to_keep, fps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94718ce6c454b5f8bf36a75d97b678c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dc1167159b4a0ea8e5cd76c74f4980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f689b2194ff745eaa5b9a34c374284e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "car_report Elapsed Time in Seconds 63.44844651222229\n",
      "car_report σ Rank 1.7204650534085255\n",
      "car_report μ Rank 1.8\n",
      "car_report Median Rank 1.0\n",
      "car_report mRR: 0.8229166666666667\n",
      "car_report mAP: 0.7260905736563632\n",
      "car_report Hit@1: 0.75\n",
      "car_report Hit@5: 0.95\n",
      "car_report Hit@10: 1.0\n",
      "king Elapsed Time in Seconds 104.19167971611023\n",
      "king σ Rank 1.0198039027185568\n",
      "king μ Rank 1.6\n",
      "king Median Rank 1.0\n",
      "king mRR: 0.7933333333333333\n",
      "king mAP: 0.6480639268139268\n",
      "king Hit@1: 0.65\n",
      "king Hit@5: 1.0\n",
      "king Hit@10: 1.0\n",
      "tasty Elapsed Time in Seconds 78.35678124427795\n",
      "tasty σ Rank 0.6403124237432849\n",
      "tasty μ Rank 1.3\n",
      "tasty Median Rank 1.0\n",
      "tasty mRR: 0.8833333333333332\n",
      "tasty mAP: 0.8186261423761423\n",
      "tasty Hit@1: 0.8\n",
      "tasty Hit@5: 1.0\n",
      "tasty Hit@10: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbea2e26dbac45668921b4fe0dff283f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf6d464039047428676e3d1077f84ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1640ebaceb304f229963ed2ce34aea51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "car_report Elapsed Time in Seconds 70.80435085296631\n",
      "car_report σ Rank 0.6782329983125267\n",
      "car_report μ Rank 1.2\n",
      "car_report Median Rank 1.0\n",
      "car_report mRR: 0.9375\n",
      "car_report mAP: 0.8619172932330826\n",
      "car_report Hit@1: 0.9\n",
      "car_report Hit@5: 1.0\n",
      "car_report Hit@10: 1.0\n",
      "king Elapsed Time in Seconds 117.23649311065674\n",
      "king σ Rank 1.061838029079765\n",
      "king μ Rank 1.65\n",
      "king Median Rank 1.0\n",
      "king mRR: 0.7849999999999999\n",
      "king mAP: 0.652819264069264\n",
      "king Hit@1: 0.65\n",
      "king Hit@5: 1.0\n",
      "king Hit@10: 1.0\n",
      "tasty Elapsed Time in Seconds 85.77620220184326\n",
      "tasty σ Rank 0.4330127018922193\n",
      "tasty μ Rank 1.25\n",
      "tasty Median Rank 1.0\n",
      "tasty mRR: 0.875\n",
      "tasty mAP: 0.828989898989899\n",
      "tasty Hit@1: 0.75\n",
      "tasty Hit@5: 1.0\n",
      "tasty Hit@10: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc88f4c02674405863bef74a0eadb71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "car_report Elapsed Time in Seconds 305.5726613998413\n",
      "car_report σ Rank 0.7810249675906654\n",
      "car_report μ Rank 1.3\n",
      "car_report Median Rank 1.0\n",
      "car_report mRR: 0.9041666666666666\n",
      "car_report mAP: 0.8371001221001222\n",
      "car_report Hit@1: 0.85\n",
      "car_report Hit@5: 1.0\n",
      "car_report Hit@10: 1.0\n",
      "king Elapsed Time in Seconds 518.4577212333679\n",
      "king σ Rank 1.1575836902790224\n",
      "king μ Rank 1.6\n",
      "king Median Rank 1.0\n",
      "king mRR: 0.8308333333333333\n",
      "king mAP: 0.7070472582972583\n",
      "king Hit@1: 0.75\n",
      "king Hit@5: 1.0\n",
      "king Hit@10: 1.0\n",
      "tasty Elapsed Time in Seconds 375.53088760375977\n",
      "tasty σ Rank 0.5099019513592785\n",
      "tasty μ Rank 1.2\n",
      "tasty Median Rank 1.0\n",
      "tasty mRR: 0.9166666666666666\n",
      "tasty mAP: 0.8701785714285715\n",
      "tasty Hit@1: 0.85\n",
      "tasty Hit@5: 1.0\n",
      "tasty Hit@10: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bb39d9a9294667a258db1287601bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ced12af7f4346cc936cc5e6334a6347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a29c66c8ffe4891a59e96ab5ad7965d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "car_report Elapsed Time in Seconds 464.14875078201294\n",
      "car_report σ Rank 0.0\n",
      "car_report μ Rank 1.0\n",
      "car_report Median Rank 1.0\n",
      "car_report mRR: 1.0\n",
      "car_report mAP: 0.9554761904761906\n",
      "car_report Hit@1: 1.0\n",
      "car_report Hit@5: 1.0\n",
      "car_report Hit@10: 1.0\n",
      "king Elapsed Time in Seconds 811.3421664237976\n",
      "king σ Rank 0.9733961166965892\n",
      "king μ Rank 1.45\n",
      "king Median Rank 1.0\n",
      "king mRR: 0.8516666666666666\n",
      "king mAP: 0.7042826617826617\n",
      "king Hit@1: 0.75\n",
      "king Hit@5: 1.0\n",
      "king Hit@10: 1.0\n",
      "tasty Elapsed Time in Seconds 535.4938454627991\n",
      "tasty σ Rank 0.47696960070847283\n",
      "tasty μ Rank 1.15\n",
      "tasty Median Rank 1.0\n",
      "tasty mRR: 0.9416666666666667\n",
      "tasty mAP: 0.8994246031746032\n",
      "tasty Hit@1: 0.9\n",
      "tasty Hit@5: 1.0\n",
      "tasty Hit@10: 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c0c9129ec544b282f13bd2f63cefe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df692f2d43a8402a88c8d009170e52d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "car_report Elapsed Time in Seconds 63.505577087402344\n",
      "car_report σ Rank 0.7399324293474372\n",
      "car_report μ Rank 1.55\n",
      "car_report Median Rank 1.0\n",
      "car_report mRR: 0.775\n",
      "car_report mAP: 0.6573383278085292\n",
      "car_report Hit@1: 0.6\n",
      "car_report Hit@5: 1.0\n",
      "car_report Hit@10: 1.0\n",
      "king Elapsed Time in Seconds 104.1245505809784\n",
      "king σ Rank 2.0099751242241775\n",
      "king μ Rank 2.4\n",
      "king Median Rank 1.5\n",
      "king mRR: 0.6675595238095238\n",
      "king mAP: 0.6095583093377211\n",
      "king Hit@1: 0.5\n",
      "king Hit@5: 0.9\n",
      "king Hit@10: 1.0\n",
      "tasty Elapsed Time in Seconds 77.87287330627441\n",
      "tasty σ Rank 0.3570714214271425\n",
      "tasty μ Rank 1.15\n",
      "tasty Median Rank 1.0\n",
      "tasty mRR: 0.925\n",
      "tasty mAP: 0.8265873015873015\n",
      "tasty Hit@1: 0.85\n",
      "tasty Hit@5: 1.0\n",
      "tasty Hit@10: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582c647f29c445b2905b9188704a2a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3906ef5ab85540b28628b47ba58c7214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0068fadcbcbb47ffb6000cbee50d63e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "car_report Elapsed Time in Seconds 70.31286430358887\n",
      "car_report σ Rank 0.7348469228349535\n",
      "car_report μ Rank 1.4\n",
      "car_report Median Rank 1.0\n",
      "car_report mRR: 0.85\n",
      "car_report mAP: 0.7136117123617124\n",
      "car_report Hit@1: 0.75\n",
      "car_report Hit@5: 1.0\n",
      "car_report Hit@10: 1.0\n",
      "king Elapsed Time in Seconds 116.2100682258606\n",
      "king σ Rank 2.0024984394500787\n",
      "king μ Rank 2.3\n",
      "king Median Rank 1.0\n",
      "king mRR: 0.6947222222222222\n",
      "king mAP: 0.6263686748980867\n",
      "king Hit@1: 0.55\n",
      "king Hit@5: 0.95\n",
      "king Hit@10: 1.0\n",
      "tasty Elapsed Time in Seconds 84.73524451255798\n",
      "tasty σ Rank 0.3\n",
      "tasty μ Rank 1.1\n",
      "tasty Median Rank 1.0\n",
      "tasty mRR: 0.95\n",
      "tasty mAP: 0.8338789682539682\n",
      "tasty Hit@1: 0.9\n",
      "tasty Hit@5: 1.0\n",
      "tasty Hit@10: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510d21eb3f4046c8aa660794d21883e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "car_report Elapsed Time in Seconds 307.9623382091522\n",
      "car_report σ Rank 1.0677078252031311\n",
      "car_report μ Rank 1.4\n",
      "car_report Median Rank 1.0\n",
      "car_report mRR: 0.8975\n",
      "car_report mAP: 0.7357682726200528\n",
      "car_report Hit@1: 0.85\n",
      "car_report Hit@5: 1.0\n",
      "car_report Hit@10: 1.0\n",
      "king Elapsed Time in Seconds 519.2798550128937\n",
      "king σ Rank 2.080264406271472\n",
      "king μ Rank 2.15\n",
      "king Median Rank 1.0\n",
      "king mRR: 0.7555555555555555\n",
      "king mAP: 0.65692606005106\n",
      "king Hit@1: 0.65\n",
      "king Hit@5: 0.9\n",
      "king Hit@10: 1.0\n",
      "tasty Elapsed Time in Seconds 375.72621512413025\n",
      "tasty σ Rank 0.0\n",
      "tasty μ Rank 1.0\n",
      "tasty Median Rank 1.0\n",
      "tasty mRR: 1.0\n",
      "tasty mAP: 0.9569444444444445\n",
      "tasty Hit@1: 1.0\n",
      "tasty Hit@5: 1.0\n",
      "tasty Hit@10: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91af626018f4ef0b1fc92c9fd860455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1996dc4124454c9a6aef18beccea0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86ead5b98814a1587c522ab105e63f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "car_report Elapsed Time in Seconds 466.4981746673584\n",
      "car_report σ Rank 0.8874119674649424\n",
      "car_report μ Rank 1.25\n",
      "car_report Median Rank 1.0\n",
      "car_report mRR: 0.9349999999999999\n",
      "car_report mAP: 0.7973933422385435\n",
      "car_report Hit@1: 0.9\n",
      "car_report Hit@5: 1.0\n",
      "car_report Hit@10: 1.0\n",
      "king Elapsed Time in Seconds 811.8493564128876\n",
      "king σ Rank 1.5960889699512368\n",
      "king μ Rank 1.95\n",
      "king Median Rank 1.0\n",
      "king mRR: 0.7613095238095238\n",
      "king mAP: 0.6506891025641026\n",
      "king Hit@1: 0.65\n",
      "king Hit@5: 0.95\n",
      "king Hit@10: 1.0\n",
      "tasty Elapsed Time in Seconds 535.5874562263489\n",
      "tasty σ Rank 0.0\n",
      "tasty μ Rank 1.0\n",
      "tasty Median Rank 1.0\n",
      "tasty mRR: 1.0\n",
      "tasty mAP: 0.945138888888889\n",
      "tasty Hit@1: 1.0\n",
      "tasty Hit@5: 1.0\n",
      "tasty Hit@10: 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2377e8cfea54f3585b6a83027c1bfe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21251435d3f74bb39cb1645b36e903e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "car_report Elapsed Time in Seconds 63.44441246986389\n",
      "car_report σ Rank 0.0\n",
      "car_report μ Rank 1.0\n",
      "car_report Median Rank 1.0\n",
      "car_report mRR: 1.0\n",
      "car_report mAP: 0.884920634920635\n",
      "car_report Hit@1: 1.0\n",
      "car_report Hit@5: 1.0\n",
      "car_report Hit@10: 1.0\n",
      "king Elapsed Time in Seconds 104.51212310791016\n",
      "king σ Rank 1.57797338380595\n",
      "king μ Rank 1.9\n",
      "king Median Rank 1.0\n",
      "king mRR: 0.7696428571428571\n",
      "king mAP: 0.7025694444444442\n",
      "king Hit@1: 0.65\n",
      "king Hit@5: 0.95\n",
      "king Hit@10: 1.0\n",
      "tasty Elapsed Time in Seconds 78.18621182441711\n",
      "tasty σ Rank 0.7810249675906654\n",
      "tasty μ Rank 1.3\n",
      "tasty Median Rank 1.0\n",
      "tasty mRR: 0.9041666666666666\n",
      "tasty mAP: 0.7999806187964082\n",
      "tasty Hit@1: 0.85\n",
      "tasty Hit@5: 1.0\n",
      "tasty Hit@10: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb74ff0334ef462fb334555adfd2971c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f990cbf77b404f8ca57d4b4b301b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56980250e1a44349b214ad05924f3fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "car_report Elapsed Time in Seconds 70.26576256752014\n",
      "car_report σ Rank 0.0\n",
      "car_report μ Rank 1.0\n",
      "car_report Median Rank 1.0\n",
      "car_report mRR: 1.0\n",
      "car_report mAP: 0.9258333333333333\n",
      "car_report Hit@1: 1.0\n",
      "car_report Hit@5: 1.0\n",
      "car_report Hit@10: 1.0\n",
      "king Elapsed Time in Seconds 116.6252670288086\n",
      "king σ Rank 1.4352700094407325\n",
      "king μ Rank 1.8\n",
      "king Median Rank 1.0\n",
      "king mRR: 0.7958333333333334\n",
      "king mAP: 0.708668990323402\n",
      "king Hit@1: 0.7\n",
      "king Hit@5: 0.95\n",
      "king Hit@10: 1.0\n",
      "tasty Elapsed Time in Seconds 85.07738757133484\n",
      "tasty σ Rank 0.47696960070847283\n",
      "tasty μ Rank 1.15\n",
      "tasty Median Rank 1.0\n",
      "tasty mRR: 0.9416666666666667\n",
      "tasty mAP: 0.8274500962000962\n",
      "tasty Hit@1: 0.9\n",
      "tasty Hit@5: 1.0\n",
      "tasty Hit@10: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1f3f733d8c4e1db7847e8728d7dd04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "car_report Elapsed Time in Seconds 308.94186758995056\n",
      "car_report σ Rank 0.21794494717703372\n",
      "car_report μ Rank 1.05\n",
      "car_report Median Rank 1.0\n",
      "car_report mRR: 0.975\n",
      "car_report mAP: 0.9564484126984126\n",
      "car_report Hit@1: 0.95\n",
      "car_report Hit@5: 1.0\n",
      "car_report Hit@10: 1.0\n",
      "king Elapsed Time in Seconds 519.4086105823517\n",
      "king σ Rank 2.118962010041709\n",
      "king μ Rank 2.1\n",
      "king Median Rank 1.0\n",
      "king mRR: 0.7591666666666667\n",
      "king mAP: 0.6873954517704518\n",
      "king Hit@1: 0.65\n",
      "king Hit@5: 0.95\n",
      "king Hit@10: 1.0\n",
      "tasty Elapsed Time in Seconds 377.120591878891\n",
      "tasty σ Rank 0.3\n",
      "tasty μ Rank 1.1\n",
      "tasty Median Rank 1.0\n",
      "tasty mRR: 0.95\n",
      "tasty mAP: 0.927142857142857\n",
      "tasty Hit@1: 0.9\n",
      "tasty Hit@5: 1.0\n",
      "tasty Hit@10: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170ad5aeb46a420999c171a92c277b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3416e8c2704c55bd76b58dad9ecdbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2c567fefe84f0bbbc9ecfbd382f9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "car_report Elapsed Time in Seconds 467.0696225166321\n",
      "car_report σ Rank 0.0\n",
      "car_report μ Rank 1.0\n",
      "car_report Median Rank 1.0\n",
      "car_report mRR: 1.0\n",
      "car_report mAP: 0.9833333333333332\n",
      "car_report Hit@1: 1.0\n",
      "car_report Hit@5: 1.0\n",
      "car_report Hit@10: 1.0\n",
      "king Elapsed Time in Seconds 810.8539173603058\n",
      "king σ Rank 1.5960889699512368\n",
      "king μ Rank 1.95\n",
      "king Median Rank 1.0\n",
      "king mRR: 0.7613095238095238\n",
      "king mAP: 0.6880222555222554\n",
      "king Hit@1: 0.65\n",
      "king Hit@5: 0.95\n",
      "king Hit@10: 1.0\n",
      "tasty Elapsed Time in Seconds 535.9586563110352\n",
      "tasty σ Rank 0.21794494717703372\n",
      "tasty μ Rank 1.05\n",
      "tasty Median Rank 1.0\n",
      "tasty mRR: 0.975\n",
      "tasty mAP: 0.9142015392015391\n",
      "tasty Hit@1: 0.95\n",
      "tasty Hit@5: 1.0\n",
      "tasty Hit@10: 1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_rankings(\n",
    "    path, vid_val_ds, ds_val, model_01, M01, simclr_frame_sim, vwords, n_imgs,\n",
    "    n_frames_to_keep, fps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afde0b914bbb4e3e81edd3cf6a54353c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16712a6c040349a092aceaff34208078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899c30bf59994f18a95cdeb924198a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "APOD Elapsed Time in Seconds 137.18566870689392\n",
      "APOD σ Rank 6.72053238631848\n",
      "APOD μ Rank 7.033333333333333\n",
      "APOD Median Rank 4.0\n",
      "APOD mRR: 0.3394523877183724\n",
      "APOD mAP: 0.258917949980462\n",
      "APOD Hit@1: 0.13333333333333333\n",
      "APOD Hit@5: 0.6\n",
      "APOD Hit@10: 0.7666666666666667\n",
      "GROW Elapsed Time in Seconds 181.32364177703857\n",
      "GROW σ Rank 4.689528263929048\n",
      "GROW μ Rank 4.516129032258065\n",
      "GROW Median Rank 2.0\n",
      "GROW mRR: 0.5774402403859109\n",
      "GROW mAP: 0.447443430985815\n",
      "GROW Hit@1: 0.4838709677419355\n",
      "GROW Hit@5: 0.6774193548387096\n",
      "GROW Hit@10: 0.9032258064516129\n",
      "TIME Elapsed Time in Seconds 154.77173161506653\n",
      "TIME σ Rank 6.728050733062784\n",
      "TIME μ Rank 10.0\n",
      "TIME Median Rank 9.5\n",
      "TIME mRR: 0.18574943704768268\n",
      "TIME mAP: 0.15163777994158123\n",
      "TIME Hit@1: 0.03333333333333333\n",
      "TIME Hit@5: 0.36666666666666664\n",
      "TIME Hit@10: 0.5666666666666667\n",
      "TOK Elapsed Time in Seconds 131.85000610351562\n",
      "TOK σ Rank 6.89895322172542\n",
      "TOK μ Rank 11.733333333333333\n",
      "TOK Median Rank 12.0\n",
      "TOK mRR: 0.14707765280416377\n",
      "TOK mAP: 0.13073919999912478\n",
      "TOK Hit@1: 0.0\n",
      "TOK Hit@5: 0.26666666666666666\n",
      "TOK Hit@10: 0.43333333333333335\n",
      "DROID Elapsed Time in Seconds 81.43422842025757\n",
      "DROID σ Rank 5.951657098844172\n",
      "DROID μ Rank 5.666666666666667\n",
      "DROID Median Rank 4.5\n",
      "DROID mRR: 0.4516127989657402\n",
      "DROID mAP: 0.37743033755820665\n",
      "DROID Hit@1: 0.3\n",
      "DROID Hit@5: 0.7\n",
      "DROID Hit@10: 0.8333333333333334\n",
      "GNU Elapsed Time in Seconds 143.46835684776306\n",
      "GNU σ Rank 5.188020388891658\n",
      "GNU μ Rank 6.133333333333334\n",
      "GNU Median Rank 4.0\n",
      "GNU mRR: 0.30873075998076\n",
      "GNU mAP: 0.26520964924769275\n",
      "GNU Hit@1: 0.06666666666666667\n",
      "GNU Hit@5: 0.6\n",
      "GNU Hit@10: 0.8333333333333334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4325bb0247743358a0551cad8025a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=435.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa9d9febbb2447c98512dfb88013c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=465.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d02f9dcfa5438e8e7e17c1f9d76767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=435.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b325fc6186f643c2ba630aedc8681dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=435.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f1835724af410791cca62f876b73eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=435.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f6ccfcdcea46318c54f9b521bf17ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=435.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "APOD Elapsed Time in Seconds 111.38591718673706\n",
      "APOD σ Rank 6.556082841317842\n",
      "APOD μ Rank 6.533333333333333\n",
      "APOD Median Rank 4.0\n",
      "APOD mRR: 0.3178536262308192\n",
      "APOD mAP: 0.2318390767154601\n",
      "APOD Hit@1: 0.1\n",
      "APOD Hit@5: 0.6\n",
      "APOD Hit@10: 0.8666666666666667\n",
      "GROW Elapsed Time in Seconds 191.25272369384766\n",
      "GROW σ Rank 7.244072534745746\n",
      "GROW μ Rank 8.67741935483871\n",
      "GROW Median Rank 7.0\n",
      "GROW mRR: 0.3540689167646514\n",
      "GROW mAP: 0.28471266207628854\n",
      "GROW Hit@1: 0.22580645161290322\n",
      "GROW Hit@5: 0.4838709677419355\n",
      "GROW Hit@10: 0.5806451612903226\n",
      "TIME Elapsed Time in Seconds 160.0667724609375\n",
      "TIME σ Rank 6.3962662719919825\n",
      "TIME μ Rank 9.433333333333334\n",
      "TIME Median Rank 8.5\n",
      "TIME mRR: 0.20449145864264542\n",
      "TIME mAP: 0.1591668891284138\n",
      "TIME Hit@1: 0.06666666666666667\n",
      "TIME Hit@5: 0.3333333333333333\n",
      "TIME Hit@10: 0.7\n",
      "TOK Elapsed Time in Seconds 118.49521207809448\n",
      "TOK σ Rank 7.008011288676855\n",
      "TOK μ Rank 11.233333333333333\n",
      "TOK Median Rank 11.0\n",
      "TOK mRR: 0.1851730466890313\n",
      "TOK mAP: 0.15000096682229513\n",
      "TOK Hit@1: 0.06666666666666667\n",
      "TOK Hit@5: 0.3333333333333333\n",
      "TOK Hit@10: 0.4666666666666667\n",
      "DROID Elapsed Time in Seconds 42.59784007072449\n",
      "DROID σ Rank 4.099457958749614\n",
      "DROID μ Rank 6.833333333333333\n",
      "DROID Median Rank 6.0\n",
      "DROID mRR: 0.2605968105968106\n",
      "DROID mAP: 0.21794291926788756\n",
      "DROID Hit@1: 0.1\n",
      "DROID Hit@5: 0.43333333333333335\n",
      "DROID Hit@10: 0.7666666666666667\n",
      "GNU Elapsed Time in Seconds 139.7770574092865\n",
      "GNU σ Rank 3.8099285499278794\n",
      "GNU μ Rank 5.533333333333333\n",
      "GNU Median Rank 5.0\n",
      "GNU mRR: 0.35947006697006695\n",
      "GNU mAP: 0.2799488079286841\n",
      "GNU Hit@1: 0.2\n",
      "GNU Hit@5: 0.6\n",
      "GNU Hit@10: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec25c3971bef4b12962c77c48f99e2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_rankings(\n",
    "    path, vid_user_ds, ds_user, model_00, M00, sift_frame_sim, vwords, n_imgs,\n",
    "    n_frames_to_keep, fps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_rankings(\n",
    "    path, vid_user_ds, ds_user, model_01, M01, simclr_frame_sim, vwords, n_imgs,\n",
    "    n_frames_to_keep, fps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rankings(\n",
    "    path, vid_ds, ds_name, model_name, model, sim_func, vwords, n_imgs,\n",
    "     n_frames_to_keep, fps\n",
    "):\n",
    "\n",
    "    for vw in tqdm(vwords):\n",
    "        for ftk in tqdm(n_frames_to_keep):\n",
    "            rankings = {}\n",
    "            evaluation_metrics = {}\n",
    "            fname = path/f'models/codebooks/{model_name}/cookbook_{model_name}_{vw}vw.model'\n",
    "            codebook = pickle.load(open(fname, 'rb'))\n",
    "            start = time.time()\n",
    "            vid_ds_features = gen_extracted_features(vid_ds, model, fps, ftk)\n",
    "            df, bovw_vid_ds_sims = gen_bovw_similarity(vid_ds, vid_ds_features, model, codebook, vw, ftk)\n",
    "            bovw_vid_ds_sims = gen_lcs_similarity(vid_ds, vid_ds_features, sim_func, mdl, codebook, df, vw, ftk)\n",
    "            \n",
    "            \n",
    "            rankings['bovw'] = approach(\n",
    "                vid_ds, vid_ds_features, vid_ds_sims, model, sim_func,\n",
    "                codebook, df, vw, fps = fps, ftk = ftk\n",
    "            )\n",
    "            end_bovw = time.time()\n",
    "            rankings['bovw_time'] = end_bovw - start\n",
    "            evaluation_metrics['bovw'] = evaluate(\n",
    "                rankings['bovw']\n",
    "            )\n",
    "            \n",
    "            rankings['lcs'] = approach(\n",
    "                vid_ds, vid_ds_features, vid_ds_sims, model, sim_func,\n",
    "                codebook, df, vw, fps = fps, ftk = ftk, mode = 'lcs'\n",
    "            )\n",
    "            end_lcs = time.time()\n",
    "            rankings['lcs_time'] = end_lcs - start\n",
    "            evaluation_metrics['lcs'] = evaluate(\n",
    "                rankings['lcs']\n",
    "            )\n",
    "\n",
    "#             rankings['bovw_lcs'] = approach(\n",
    "#                 vid_ds, vid_ds_features, vid_ds_sims, model, sim_func,\n",
    "#                 codebook, df, vw, fps = fps, ftk = ftk, mode = 'bovw_lcs'\n",
    "#             )\n",
    "#             end_bovw_lcs = time.time()\n",
    "#             rankings['bovw_lcs_time'] = end_bovw_lcs - start\n",
    "#             evaluation_metrics['bovw_lcs'] = evaluate(\n",
    "#                 rankings['bovw_lcs']\n",
    "#             )\n",
    "            \n",
    "            id_name = f'{ds_name}_{n_imgs}n_{vw}vw_{ftk}ftk'\n",
    "            with open(path/f'results/{model_name}/rankings_{id_name}_lcs.pkl', 'wb') as f:\n",
    "                pickle.dump(rankings, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            with open(path/f'results/{model_name}/evaluation_metrics_{id_name}_lcs.pkl', 'wb') as f:\n",
    "                pickle.dump(evaluation_metrics, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "rico_path = Path('/tf/data/combined/data')\n",
    "img_paths = sorted(rico_path.glob('*.jpg'))\n",
    "\n",
    "n = 1_000\n",
    "sampled_imgs = [Image.open(img) for img in sample(img_paths, n)]\n",
    "len(sampled_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/tf/data/datasets/validation_videos\")\n",
    "vid_ds = VideoDataset.from_path(path).label_from_paths()\n",
    "vid_ds.get_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define different models to run experiments on:\n",
    "- SIFT baseline model - (M01)\n",
    "- CNN non-layered non-finetuned baseline model - (M02)\n",
    "- CNN non-layered finetuned baseline model - (M03)\n",
    "- CNN layered non-finetuned baseline model - (M04)\n",
    "- CNN layered finetuned baseline model - (M05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT based models:\n",
    "M00 = SIFTExtractor(cv2.xfeatures2d.SIFT_create())\n",
    "\n",
    "# CNN based models:\n",
    "model = SimCLRModel.load_from_checkpoint(checkpoint_path='/tf/data/models/simclr/checkpointepoch=98.ckpt').eval()\n",
    "M01 = SimCLRExtractor(model)\n",
    "# M01 = CNNExtractor(createExtractor(None, None, 'resnet50', False))\n",
    "# learn, linear_output_layer = cnn.trainPetsModel() # Need to change to training on android screenshots\n",
    "# M02 = CNNExtractor(cnn.createExtractor(learn, linear_output_layer, 'resnet50', True))\n",
    "# M03 = CNNExtractor(createLayeredExtractor()) # TODO: Rego over implementation as it doesn't seem to generate multiple visual codebooks\n",
    "# Need to create code for using finetuned layered cnn model M05\n",
    "\n",
    "models_under_study = [M00, M01] # [M01, M02, M04]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_all_codebooks(imgs, models, vw):\n",
    "    for i, model in enumerate(models):\n",
    "        codebook = gen_vcodebook(imgs, model, vw)\n",
    "        fname = f'/tf/data/models/cookbook_M{i:02}_{len(imgs)}n_{vw}vw.model'\n",
    "        pickle.dump(codebook, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vw = 100\n",
    "gen_all_codebooks(sampled_imgs, models_under_study, vw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 01\n",
    "Ability for each model to detect duplicate bug report videos.\n",
    "\n",
    "**TODO:** Need to vary hyperparameters of different values such as number of visual words to include in codebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tfidfs(vid_ds, mdl, vw, codebook, df, ftk):\n",
    "#     vid_tfids = results = defaultdict(\n",
    "#         lambda: defaultdict(list)\n",
    "#     )\n",
    "    vid_tfids = defaultdict(\n",
    "        lambda: defaultdict(list)\n",
    "    )\n",
    "    for app, reports in tqdm(vid_ds.labels.items()):\n",
    "        for i, (report, vids) in enumerate(reports.items()):\n",
    "            for vid in vids:\n",
    "                bovw = new_get_bovw(vid, mdl, codebook, vw, frames_to_keep = ftk)\n",
    "                vid_tfids[app][report].append(calc_tf_idf(bovw, df))\n",
    "    \n",
    "    return vid_tfids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(vid_ds, imgs, mdls, vw, ftk):\n",
    "    results = {}\n",
    "    \n",
    "    for m, mdl in enumerate(mdls):\n",
    "        fname = f'/tf/data/models/cookbook_M{m:02}_{len(imgs)}n_{vw}vw.model'\n",
    "        codebook = pickle.load(open(fname, 'rb'))\n",
    "        results[f'M{m:02}-{vw}'] = {}\n",
    "        df = get_df(imgs, mdl, codebook, vw)\n",
    "        print(df)\n",
    "        vid_tfids = gen_tfidfs(vid_ds, mdl, vw, codebook, df, ftk)\n",
    "        for app, reports in vid_ds.labels.items():\n",
    "            results[f'M{m:02}-{vw}'][app] = {}\n",
    "            for report_i in reports:\n",
    "                results[f'M{m:02}-{vw}'][app][report_i] = {}\n",
    "                for report_j in reports:\n",
    "                    results[f'M{m:02}-{vw}'][app][report_i][report_j] = {}\n",
    "                    for k in range(len(vid_tfids[app][report_i])):\n",
    "                        results[f'M{m:02}-{vw}'][app][report_i][report_j][f'vid_{k}'] = {}\n",
    "                        for l in range(len(vid_tfids[app][report_j])):\n",
    "                            results[f'M{m:02}-{vw}'][app][report_i][report_j][f'vid_{k}'][f'vid_{l}'] = np.dot(vid_tfids[app][report_i][k], vid_tfids[app][report_j][l]) / (np.linalg.norm(vid_tfids[app][report_i][k]) * np.linalg.norm(vid_tfids[app][report_j][l]))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = get_results(vid_ds, sampled_imgs, models_under_study, vw, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(d_in, d_out, parent_key):\n",
    "    for k, v in d_in.items():\n",
    "        if isinstance(v, dict):\n",
    "            flatten_dict(v, d_out, parent_key + (k,))\n",
    "        else:\n",
    "            d_out[parent_key + (k,)] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_results(results):\n",
    "    sorted_results = {}\n",
    "    for m in results:\n",
    "        sorted_results[m] = {}\n",
    "        for app in results[m]:\n",
    "            sorted_results[m][app] = {}\n",
    "            d_out = {}\n",
    "            flatten_dict(results[m][app], d_out, tuple())\n",
    "            sorted_results[m][app] = OrderedDict(\n",
    "                sorted(d_out.items(), key=lambda x: x[1], reverse = True)\n",
    "            )\n",
    "    \n",
    "    return sorted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results = sort_results(results)\n",
    "pprint(sorted_results['M01-10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(sorted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_codebooks = {}\n",
    "num_vwords = [100,]\n",
    "for vwords in tqdm(num_vwords):\n",
    "    for i, model in tqdm(enumerate(models_under_study), total = len(models_under_study)):\n",
    "        codebook = gen_vcodebook(imgs, model, vwords)\n",
    "        model_codebooks[f'M{i + 1:02}-{vwords}'] = codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tfidfs(vid_ds, df):\n",
    "    vid_tfids = results = defaultdict(\n",
    "        lambda: defaultdict(list)\n",
    "    )\n",
    "    for app, reports in tqdm(vid_ds.labels.items()):\n",
    "        for i, (report, vids) in enumerate(reports.items()):\n",
    "            for vid in vids:\n",
    "                bovw = new_get_bovw(vid.vid_path, model, codebook, vwords, n = 500)\n",
    "                vid_tfids[app][report].append(calc_tf_idf(hist, df))\n",
    "    \n",
    "    return vid_tfids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(vid_ds, imgs, models, model_codebooks, num_vwords):\n",
    "    results = {}\n",
    "    \n",
    "    for vwords in num_vwords:\n",
    "        for m, (model, (key, codebook)) in enumerate(zip(models, model_codebooks.items())):\n",
    "            results[f'M{m + 1:02}-{vwords}'] = {}\n",
    "            df = get_df(imgs, model, codebook, vwords)\n",
    "            vid_tfids = gen_tfidfs(vid_ds, df)\n",
    "            for app, reports in vid_ds.labels.items():\n",
    "                results[f'M{m + 1:02}-{vwords}'][app] = {}\n",
    "                for report_i in reports:\n",
    "                    results[f'M{m + 1:02}-{vwords}'][app][report_i] = {}\n",
    "                    for report_j in reports:\n",
    "                        results[f'M{m + 1:02}-{vwords}'][app][report_i][report_j] = {}\n",
    "                        for k in range(len(vid_tfids[app][report_i])):\n",
    "                            results[f'M{m + 1:02}-{vwords}'][app][report_i][report_j][f'vid_{k}'] = {}\n",
    "                            for l in range(len(vid_tfids[app][report_j])):\n",
    "                                results[f'M{m + 1:02}-{vwords}'][app][report_i][report_j][f'vid_{k}'][f'vid_{l}'] = np.dot(vid_tfids[app][report_i][k], vid_tfids[app][report_j][l]) / (np.linalg.norm(vid_tfids[app][report_i][k]) * np.linalg.norm(vid_tfids[app][report_j][l]))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = get_results(vid_ds, imgs, models_under_study, model_codebooks, num_vwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(d_in, d_out, parent_key):\n",
    "    for k, v in d_in.items():\n",
    "        if isinstance(v, dict):\n",
    "            flatten_dict(v, d_out, parent_key + (k,))\n",
    "        else:\n",
    "            d_out[parent_key + (k,)] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_results(results):\n",
    "    sorted_results = {}\n",
    "    for m in results:\n",
    "        sorted_results[m] = {}\n",
    "        for app in results[m]:\n",
    "            sorted_results[m][app] = {}\n",
    "            d_out = {}\n",
    "            flatten_dict(results[m][app], d_out, tuple())\n",
    "            sorted_results[m][app] = OrderedDict(\n",
    "                sorted(d_out.items(), key=lambda x: x[1], reverse = True)\n",
    "            )\n",
    "    \n",
    "    return sorted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results = sort_results(results)\n",
    "pprint(sorted_results['M01-10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(sorted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in sorted_results:\n",
    "    rs = []\n",
    "    for app in sorted_results[model]:\n",
    "        r = []\n",
    "        for labels, score in sorted_results[model][app].items():\n",
    "            if labels[0] == 'S01':\n",
    "                if labels[2] != labels[3]:\n",
    "                    if labels[0] == labels[1]: r.append(1)\n",
    "                    else: r.append(0)\n",
    "        rs.append(r)\n",
    "    \n",
    "    print(f'{model} mAP:', mean_average_precision(rs))\n",
    "    print(f'{model} mRR:', mean_reciprocal_rank(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reciprocal_rank(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reciprocal_rank(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_average_precision(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_average_precision(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1, r2, r3 = [], [], []\n",
    "for labels, score in sorted_results['M01-100']['car_part'].items():\n",
    "    if labels[0] == 'S01':\n",
    "        if labels[2] != labels[3]:\n",
    "            if labels[0] == labels[1]: r1.append(1)\n",
    "            else: r1.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_average_precision([r1, r2, r3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision(r1), average_precision(r2), average_precision(r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2, r3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for labels, score in sorted_results['M01-100']['car_part'].items():\n",
    "    if labels[0] == 'S02':\n",
    "        print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_results['M01-100']['car_part']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def mean_reciprocal_rank(rs):\n",
    "    \"\"\"Score is reciprocal of the rank of the first relevant item\n",
    "\n",
    "    First element is 'rank 1'.  Relevance is binary (nonzero is relevant).\n",
    "\n",
    "    Example from http://en.wikipedia.org/wiki/Mean_reciprocal_rank\n",
    "    >>> rs = [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n",
    "    >>> mean_reciprocal_rank(rs)\n",
    "    0.61111111111111105\n",
    "    >>> rs = np.array([[0, 0, 0], [0, 1, 0], [1, 0, 0]])\n",
    "    >>> mean_reciprocal_rank(rs)\n",
    "    0.5\n",
    "    >>> rs = [[0, 0, 0, 1], [1, 0, 0], [1, 0, 0]]\n",
    "    >>> mean_reciprocal_rank(rs)\n",
    "    0.75\n",
    "\n",
    "    Args:\n",
    "        rs: Iterator of relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "\n",
    "    Returns:\n",
    "        Mean reciprocal rank\n",
    "    \"\"\"\n",
    "    rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
    "    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
    "\n",
    "def r_precision(r):\n",
    "    \"\"\"Score is precision after all relevant documents have been retrieved\n",
    "\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "\n",
    "    >>> r = [0, 0, 1]\n",
    "    >>> r_precision(r)\n",
    "    0.33333333333333331\n",
    "    >>> r = [0, 1, 0]\n",
    "    >>> r_precision(r)\n",
    "    0.5\n",
    "    >>> r = [1, 0, 0]\n",
    "    >>> r_precision(r)\n",
    "    1.0\n",
    "\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "\n",
    "    Returns:\n",
    "        R Precision\n",
    "    \"\"\"\n",
    "    r = np.asarray(r) != 0\n",
    "    z = r.nonzero()[0]\n",
    "    if not z.size:\n",
    "        return 0.\n",
    "    return np.mean(r[:z[-1] + 1])\n",
    "\n",
    "\n",
    "def precision_at_k(r, k):\n",
    "    \"\"\"Score is precision @ k\n",
    "\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "\n",
    "    >>> r = [0, 0, 1]\n",
    "    >>> precision_at_k(r, 1)\n",
    "    0.0\n",
    "    >>> precision_at_k(r, 2)\n",
    "    0.0\n",
    "    >>> precision_at_k(r, 3)\n",
    "    0.33333333333333331\n",
    "    >>> precision_at_k(r, 4)\n",
    "    Traceback (most recent call last):\n",
    "        File \"<stdin>\", line 1, in ?\n",
    "    ValueError: Relevance score length < k\n",
    "\n",
    "\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "\n",
    "    Returns:\n",
    "        Precision @ k\n",
    "\n",
    "    Raises:\n",
    "        ValueError: len(r) must be >= k\n",
    "    \"\"\"\n",
    "    assert k >= 1\n",
    "    r = np.asarray(r)[:k] != 0\n",
    "    if r.size != k:\n",
    "        raise ValueError('Relevance score length < k')\n",
    "    return np.mean(r)\n",
    "\n",
    "\n",
    "def average_precision(r):\n",
    "    \"\"\"Score is average precision (area under PR curve)\n",
    "\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "\n",
    "    >>> r = [1, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
    "    >>> delta_r = 1. / sum(r)\n",
    "    >>> sum([sum(r[:x + 1]) / (x + 1.) * delta_r for x, y in enumerate(r) if y])\n",
    "    0.7833333333333333\n",
    "    >>> average_precision(r)\n",
    "    0.78333333333333333\n",
    "\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "\n",
    "    Returns:\n",
    "        Average precision\n",
    "    \"\"\"\n",
    "    r = np.asarray(r) != 0\n",
    "    out = [precision_at_k(r, k + 1) for k in range(r.size) if r[k]]\n",
    "    if not out:\n",
    "        return 0.\n",
    "    return np.mean(out)\n",
    "\n",
    "\n",
    "def mean_average_precision(rs):\n",
    "    \"\"\"Score is mean average precision\n",
    "\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "\n",
    "    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1]]\n",
    "    >>> mean_average_precision(rs)\n",
    "    0.78333333333333333\n",
    "    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1], [0]]\n",
    "    >>> mean_average_precision(rs)\n",
    "    0.39166666666666666\n",
    "\n",
    "    Args:\n",
    "        rs: Iterator of relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "\n",
    "    Returns:\n",
    "        Mean average precision\n",
    "    \"\"\"\n",
    "    return np.mean([average_precision(r) for r in rs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(results['M02-100']['car_part']['S01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['M02-100']['car_part']['S01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Reduce frames per second (try difference numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_results = sort_results(results)\n",
    "pprint(sorted_results['M01-100']['car_part'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(sorted_results['M02-100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(vid_ds, imgs, models, model_codebooks, num_vwords):\n",
    "    results = defaultdict(\n",
    "        lambda: defaultdict(\n",
    "            lambda: defaultdict(\n",
    "                lambda: defaultdict(\n",
    "                    lambda: defaultdict(\n",
    "                        lambda: defaultdict(float)\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    for vwords in num_vwords:\n",
    "        for i, (model, (key, codebook)) in enumerate(zip(models, model_codebooks.items())):\n",
    "            df = get_df(imgs, model, codebook, vwords)\n",
    "            for app, reports in vid_ds.labels.items():\n",
    "                for report_i, vids_i in reports.items():\n",
    "                    for report_j, vids_j in reports.items():\n",
    "                        for j, vid_i in enumerate(vids_i):\n",
    "                            for k, vid_j in enumerate(vids_j):\n",
    "                                hist_1, bovw_1 = get_bovw(vid_i.vid_path, model, codebook, vwords, n = 100)\n",
    "                                tf_idf_1 = calc_tf_idf(hist_1, df)\n",
    "                                hist_2, bovw_2 = get_bovw(vid_j.vid_path, model, codebook, vwords, n = 100)\n",
    "                                tf_idf_2 = calc_tf_idf(hist_2, df)\n",
    "                                results[f'M{i + 1:02}-{vwords}'][app][report_i][report_j][f'vid_{j}'][f'vid_{k}'] = np.dot(tf_idf_1, tf_idf_2) / (np.linalg.norm(tf_idf_1) * np.linalg.norm(tf_idf_2))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_results(vid_ds, imgs, models_under_study, model_codebooks, num_vwords); results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['M01-100']['king_james']['S01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bovw = get_bovw(vid_ds['king_james']['S01'][0].vid_path, M01, model_codebooks['00-100'], 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "plt.bar(range(vwords), hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = Path(\"/tf/data/results\")\n",
    "model_name = 'M01'\n",
    "fname = path2/f'{model_name}/val/rankings_val_15000n_10000vw_5ftk.pkl'\n",
    "rankings = pickle.load(open(fname, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

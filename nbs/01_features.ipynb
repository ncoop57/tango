{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "\n",
    "> This module contains all the necessary functions for extracting and organizing features from videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import cv2\n",
    "import ffmpeg\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "\n",
    "# tango\n",
    "from tango.prep import *\n",
    "\n",
    "from tango.cnn import *\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Extractor(ABC):\n",
    " \n",
    "    def __init__(self, extractor):\n",
    "        self.extractor = extractor\n",
    "        super().__init__()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def extract(self, img):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SIFTExtractor(Extractor):\n",
    "\n",
    "    def extract(self, img):\n",
    "        _, features = self.extractor.detectAndCompute(img, None)\n",
    "        return features\n",
    "    \n",
    "class CNNExtractor(Extractor):\n",
    "   \n",
    "    '''Exposed CNNExtractor class used for retrieving features.'''\n",
    "\n",
    "    def extract(self, img):\n",
    "        return self.extractor.getFeatures(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = get_rand_imgs(video_paths[0], 30_000, n = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Three different techniques for feature extraction.'''\n",
    "learn, linear_output_layer = cnn.trainPetsModel()\n",
    "extractor = CNNExtractor(cnn.createExtractor(None, None, 'resnet50', False))\n",
    "extractor = CNNExtractor(cnn.createLayeredExtractor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Using the extractor to get the features.'''\n",
    "features = extractor.extract(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def gen_vcodebook(imgs, extractor, vwords = 10_000):\n",
    "    \"\"\"\n",
    "        Constructs a visual codebook based on the given images.\n",
    "        You can change vwords to increase the vocabulary of the codebook.\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    for img in imgs:\n",
    "        features = extractor.extract(img)\n",
    "        features_list.extend(features)\n",
    "    \n",
    "    codebook = KMeans(n_clusters = vwords)\n",
    "    codebook.fit(features_list)\n",
    "    \n",
    "    return codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwords = 20\n",
    "codebook = gen_vcodebook(imgs, extractor, vwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "labels = codebook.predict(features)\n",
    "hist = np.histogram(labels, bins = vwords)\n",
    "plt.bar(range(vwords), hist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_df(imgs, extractor, codebook):\n",
    "    \"\"\"Generates the document frequency for the visual words\"\"\"\n",
    "    hist = None\n",
    "    for img in imgs:\n",
    "        features = extractor.extract(img);\n",
    "        vw = codebook.predict(features)\n",
    "        if hist is not None:\n",
    "            hist += np.clip(np.histogram(vw, bins = vwords)[0], 0, 1)\n",
    "        else:\n",
    "            hist = np.clip(np.histogram(vw, bins = vwords)[0], 0, 1)\n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df(imgs, extractor, codebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "plt.bar(range(vwords), df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_bovw(vid_path, extractor, codebook):\n",
    "    \"\"\"Generates the bag of visual words (bovw) for an entire video.\"\"\"\n",
    "    vid = cv2.VideoCapture(str(vid_path))\n",
    "    \n",
    "    # checks whether frames were extracted \n",
    "    success = 1\n",
    "    bovw = np.array([])\n",
    "    for i in progress_bar(range(100)):\n",
    "        # vid object calls read \n",
    "        # function extract frames \n",
    "        success, img = vid.read() \n",
    "        if success:\n",
    "            features = extractor.extract(img)\n",
    "            vw = codebook.predict(features)\n",
    "            bovw = np.concatenate((bovw, vw))\n",
    "    \n",
    "    hist = np.histogram(bovw, bins = vwords)[0]\n",
    "    return hist, bovw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bovw = get_bovw(video_paths[3], extractor, codebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "plt.bar(range(vwords), hist)\n",
    "plt.show()\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calc_tf_idf(tfs, dfs):\n",
    "    tf_idf = np.array([])\n",
    "    for tf, df in zip(tfs, dfs):\n",
    "        tf = tf / np.sum(tfs)\n",
    "        idf = np.log(len(tfs) / (df + 1))\n",
    "        tf_idf = np.append(tf_idf, tf * idf)\n",
    "    \n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_pix2 = calc_tf_idf(hist, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "hist2, bovw2 = get_bovw(video_paths[2], extractor, codebook)\n",
    "tf_idf_pix1 = calc_tf_idf(hist2, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "hist3, bovw3 = get_bovw(video_paths[4], extractor, codebook)\n",
    "tf_idf_car1 = calc_tf_idf(hist3, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "hist4, bow4 = get_bovw(video_paths[5], extractor, codebook)\n",
    "tf_idf_car2 = calc_tf_idf(hist4, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "np.dot(tf_idf_pix1, tf_idf_pix2) / (np.linalg.norm(tf_idf_pix1) * np.linalg.norm(tf_idf_pix2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "np.dot(tf_idf_car1, tf_idf_car2) / (np.linalg.norm(tf_idf_car1) * np.linalg.norm(tf_idf_car2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "np.dot(tf_idf_pix1, tf_idf_car1) / (np.linalg.norm(tf_idf_pix1) * np.linalg.norm(tf_idf_car1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "np.dot(tf_idf_pix2, tf_idf_car2) / (np.linalg.norm(tf_idf_pix2) * np.linalg.norm(tf_idf_car2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "np.dot(tf_idf_pix1, tf_idf_pix1) / (np.linalg.norm(tf_idf_pix1) * np.linalg.norm(tf_idf_pix1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "np.dot(tf_idf_car1, tf_idf_car1) / (np.linalg.norm(tf_idf_car1) * np.linalg.norm(tf_idf_car1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%%HTML\n",
    "<video width=\"420\" height=\"315\" controls autoplay>\n",
    "    <source src=\"../../data/datasets/videos/art_and_design/pixel_art_paint/scenario2/video.mp4\" type=\"video/mp4\"/>\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%%HTML\n",
    "<video width=\"420\" height=\"315\" controls autoplay>\n",
    "    <source src=\"../../data/datasets/videos/art_and_design/pixel_art_paint/scenario1/video.mp4\" type=\"video/mp4\"/>\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%%HTML\n",
    "<video width=\"420\" height=\"315\" controls autoplay>\n",
    "    <source src=\"../../data/datasets/videos/auto_and_vehicles/car_part/scenario1/video.mp4\" type=\"video/mp4\"/>\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_prep.ipynb.\n",
      "Converted 01_features.ipynb.\n",
      "Converted 02_eval.ipynb.\n",
      "Converted 03_cnn.ipynb.\n",
      "Converted android_cnn.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted lesson1-pets.ipynb.\n",
      "Converted replicate_lesson1_pets.ipynb.\n",
      "Converted test.ipynb.\n",
      "Converted test2.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

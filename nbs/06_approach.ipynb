{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach\n",
    "\n",
    "\n",
    "> This module contains all the code for defining the various approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import copy\n",
    "import cv2\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict, OrderedDict\n",
    "from itertools import combinations_with_replacement\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "\n",
    "# tango\n",
    "from tango.eval import *\n",
    "from tango.features import *\n",
    "from tango.model import *\n",
    "from tango.prep import *\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_all_codebooks(imgs, models, vw):\n",
    "    for i, model in enumerate(models):\n",
    "        codebook = gen_vcodebook(imgs, model, vw)\n",
    "        fname = f'/tf/data/models/cookbook_M{i:02}_{len(imgs)}n_{vw}vw.model'\n",
    "        pickle.dump(codebook, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tfidfs(vid_ds, mdl, vw, codebook, df, ftk):\n",
    "    vid_tfids = defaultdict(\n",
    "        lambda: defaultdict(list)\n",
    "    )\n",
    "    for app, reports in tqdm(vid_ds.labels.items()):\n",
    "#         if app != 'car_report': continue\n",
    "        print(app)\n",
    "        for i, (report, vids) in enumerate(reports.items()):\n",
    "            for vid in vids:\n",
    "                bovw = new_get_bovw(vid, mdl, codebook, vw, frames_to_keep = ftk)\n",
    "                vid_tfids[app][report].append(calc_tf_idf(bovw, df))\n",
    "    \n",
    "    return vid_tfids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_similarity(vid_ds, mdl, codebook, vw, ftk):\n",
    "#     results = {}\n",
    "    \n",
    "#     df = np.histogram(codebook.labels_, bins = range(vw + 1))[0]\n",
    "#     vid_tfids = gen_tfidfs(vid_ds, mdl, vw, codebook, df, ftk)\n",
    "#     for app, reports in vid_ds.labels.items():\n",
    "#         if app != 'car_report': continue\n",
    "#         results[app] = {}\n",
    "#         for report_i in reports:\n",
    "#             results[app][report_i] = {}\n",
    "#             for report_j in reports:\n",
    "#                 results[app][report_i][report_j] = {}\n",
    "#                 for k in range(len(vid_tfids[app][report_i])):\n",
    "#                     results[app][report_i][report_j][f'vid_{k}'] = {}\n",
    "#                     for l in range(len(vid_tfids[app][report_j])):\n",
    "#                         results[app][report_i][report_j][f'vid_{k}'][f'vid_{l}'] = np.dot(vid_tfids[app][report_i][k], vid_tfids[app][report_j][l]) / (np.linalg.norm(vid_tfids[app][report_i][k]) * np.linalg.norm(vid_tfids[app][report_j][l]))\n",
    "    \n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_similarity(vid_ds, mdl, codebook, vw, ftk):\n",
    "    results = defaultdict(\n",
    "        lambda: defaultdict(\n",
    "            lambda: defaultdict(\n",
    "                lambda: defaultdict(\n",
    "                    lambda: defaultdict(int)\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    df = np.histogram(codebook.labels_, bins = range(vw + 1))[0]\n",
    "    vid_tfids = gen_tfidfs(vid_ds, mdl, vw, codebook, df, ftk)\n",
    "    for app, reports in vid_ds.labels.items():\n",
    "#         if app != 'car_report': continue\n",
    "        l = [(report, i) for report in reports for i in range(len(reports[report]))]\n",
    "        pairs = list(x for x in combinations_with_replacement(l, 2) if x[0] != x[1])\n",
    "        for (report_i, i), (report_j, j) in pairs:\n",
    "            results[app][report_i][f'vid_{i}'][report_j][f'vid_{j}'] = np.dot(vid_tfids[app][report_i][i], vid_tfids[app][report_j][j]) / (np.linalg.norm(vid_tfids[app][report_i][i]) * np.linalg.norm(vid_tfids[app][report_j][j]))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_vids(vid_similarities, mdl_vid_threshold = 0.8):\n",
    "    vid_dict = copy.deepcopy(vid_similarities)\n",
    "    for app in vid_dict:\n",
    "        for report_i in vid_dict[app]:\n",
    "            for report_j in vid_dict[app][report_i]:\n",
    "                for vid_i in vid_dict[app][report_i][report_j]:\n",
    "                    for vid_j in vid_dict[app][report_i][report_j][vid_i]:\n",
    "                        if vid_dict[app][report_i][report_j][vid_i] < mdl_threshold:\n",
    "                            del vid_dict[app][report_i][report_j][vid_i]\n",
    "    \n",
    "    return vid_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_frame_sim(mdl, codebook, frame_i, frame_j, vw, mdl_frame_threshold):\n",
    "    if frame_i is None or frame_j is None: return 0\n",
    "    features_i = mdl.extract(frame_i)\n",
    "    vws_i = np.expand_dims(codebook.predict(features_i), axis=0)\n",
    "    bowv_i = np.expand_dims(np.histogram(vws_i, bins = range(vw + 1))[0], axis=0)\n",
    "    \n",
    "    features_j = mdl.extract(frame_j)\n",
    "    vws_j = np.expand_dims(codebook.predict(features_j), axis=0)\n",
    "    bowv_j = np.expand_dims(np.histogram(vws_j, bins = range(vw + 1))[0], axis=0)\n",
    "    \n",
    "    sim = cosine_similarity(bowv_i, bowv_j)[0][0]\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simclr_frame_sim(mdl, codebook, frame_i, frame_j, vw, mdl_frame_threshold):\n",
    "    if frame_i is None or frame_j is None: return 0\n",
    "    features_i = mdl.extract(frame_i)\n",
    "    features_j = mdl.extract(frame_j)\n",
    "    \n",
    "    sim = cosine_similarity(features_i, features_j)[0][0]\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from geeksforgeeks: https://www.geeksforgeeks.org/longest-common-substring-dp-29/\n",
    "def fuzzy_LCS(X, Y, m, n, sim_func, mdl, codebook, vw, mdl_frame_threshold, fps = 30, frames_to_keep = 1):\n",
    "    LCSuff = [[0 for k in range(n + 1)] for l in range(m + 1)] \n",
    "      \n",
    "    # To store the length of  \n",
    "    # longest common substring \n",
    "    result = 0 \n",
    "  \n",
    "    # Following steps to build \n",
    "    # LCSuff[m+1][n+1] in bottom up fashion \n",
    "    for i in range(0, m + 1):\n",
    "        for j in range(0, n + 1):\n",
    "            if (i == 0 or j == 0): \n",
    "                LCSuff[i][j] = 0\n",
    "                continue\n",
    "            sim = sim_func(mdl, codebook, X[i * int(fps / frames_to_keep) -1], Y[j * int(fps / frames_to_keep) -1], vw, mdl_frame_threshold)\n",
    "#             print('SIM:', sim)\n",
    "            if sim > mdl_frame_threshold: \n",
    "                LCSuff[i][j] = LCSuff[i-1][j-1] + sim\n",
    "                result = max(result, LCSuff[i][j]) \n",
    "            else: \n",
    "                LCSuff[i][j] = 0\n",
    "    print('Fuzzy:', result, min(m, n))\n",
    "    return result / min(m, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(d_in, d_out, parent_key):\n",
    "    for k, v in d_in.items():\n",
    "        if isinstance(v, dict):\n",
    "            flatten_dict(v, d_out, parent_key + (k,))\n",
    "        else:\n",
    "            d_out[parent_key + (k,)] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_corpus(results, corpus_size):\n",
    "    \n",
    "    for app in results:\n",
    "#         corpus_size = len(results[app])\n",
    "        s0 = 0\n",
    "        v0 = 1\n",
    "        for i in range(corpus_size):\n",
    "            if v0 % 4 == 0: s0 += 1\n",
    "            s1 = 0\n",
    "            for v1 in range(i + 1):\n",
    "                if v1 % 4 == 0: s1 += 1\n",
    "                results[app][f'S{s0}'][f'vid_{v0 % 4}'][f'S{s1 - 1}'][f'vid_{v1 % 4}'] = results[app][f'S{s1 - 1}'][f'vid_{v1 % 4}'][f'S{s0}'][f'vid_{v0 % 4}']\n",
    "#                 results[app][f'S{s0}'][f'vid_{v0 % 4}'][(f'S{s1 - 1}', f'vid_{v1 % 4}')] = results[app][f'S{s1 - 1}'][f'vid_{v1 % 4}'][(f'S{s0}', f'vid_{v0 % 4}')]\n",
    "                \n",
    "#             print('-' * 5)\n",
    "            v0 += 1\n",
    "    return results\n",
    "#     print(i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_results(results):\n",
    "    sorted_results = {}\n",
    "    for app in results:\n",
    "        sorted_results[app] = {}\n",
    "        for report in results[app]:\n",
    "            sorted_results[app][report] = {}\n",
    "            for vid in results[app][report]:\n",
    "                sorted_results[app][report][vid] = []\n",
    "                d_out = {}\n",
    "                flatten_dict(results[app][report][vid], d_out, tuple())\n",
    "                sorted_results[app][report][vid] = OrderedDict(\n",
    "                    sorted(d_out.items(), key=lambda x: x[1], reverse = True)\n",
    "                )\n",
    "    \n",
    "    return sorted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approach(\n",
    "    vid_ds, mdl, mdl_vid_threshold, sim_func,\n",
    "    mdl_frame_threshold, codebook, vw, corpus_size,\n",
    "    fps = 30, ftk = 1, align_sim = False\n",
    "):\n",
    "    vid_ds_sims = gen_similarity(vid_ds, mdl, codebook, vw, ftk)\n",
    "    if align_sim:\n",
    "        for app, reports in vid_ds.labels.items():\n",
    "    #         if app != 'car_report': continue\n",
    "            l = [(report, i) for report in reports for i in range(len(reports[report]))]\n",
    "            pairs = list(x for x in combinations_with_replacement(l, 2) if x[0] != x[1])\n",
    "            for (report_i, i), (report_j, j) in tqdm(pairs):\n",
    "                tfidf_sim = vid_ds_sims[app][report_i][f'vid_{i}'][report_j][f'vid_{j}']\n",
    "                lcs_sim = fuzzy_LCS(\n",
    "                    vid_ds[app][report_i][i], vid_ds[app][report_j][j],\n",
    "                    int(len(vid_ds[app][report_i][i]) / int(fps / ftk)),\n",
    "                    int(len(vid_ds[app][report_j][j]) / int(fps / ftk)),\n",
    "                    sim_func, mdl, codebook, vw, mdl_frame_threshold, fps, ftk\n",
    "                )\n",
    "                vid_ds_sims[app][report_i][f'vid_{i}'][report_j][f'vid_{j}'] = (tfidf_sim + lcs_sim) / 2\n",
    "#     for app, reports in vid_ds.labels.items():\n",
    "#         if app != 'car_report': continue\n",
    "#         for i, report_i in tqdm(enumerate(reports), total = len(reports)):\n",
    "# #             if i > 1: break\n",
    "#             for j, report_j in tqdm(enumerate(reports), total = len(reports)):\n",
    "# #                 if j > 1: break\n",
    "#                 for k in range(len(vid_ds[app][report_i])):\n",
    "# #                     if k > 1: break\n",
    "#                     for l in range(len(vid_ds[app][report_j])):\n",
    "# #                         if l > 1: break\n",
    "#                         tfidf_sim = vid_ds_sims[app][report_i][report_j][f'vid_{k}'][f'vid_{l}']\n",
    "#                         lcs_sim = fuzzy_LCS(\n",
    "#                             vid_ds[app][report_i][k], vid_ds[app][report_j][l],\n",
    "#                             int(len(vid_ds[app][report_i][k]) / int(fps / ftk)), int(len(vid_ds[app][report_i][l]) / int(fps / ftk)),\n",
    "#                             sim_func, mdl, codebook, vw, mdl_frame_threshold, fps, ftk\n",
    "#                         )\n",
    "#                         print(tfidf_sim, lcs_sim)\n",
    "#                         vid_ds_sims[app][report_i][report_j][f'vid_{k}'][f'vid_{l}'] = (tfidf_sim + lcs_sim) / 2\n",
    "#     print(vid_ds_sims)\n",
    "\n",
    "    vid_ds_sims = fix_corpus(vid_ds_sims, corpus_size)\n",
    "    results = sort_results(vid_ds_sims)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_results(evals, app, item):\n",
    "    for s in evals[app]:\n",
    "        for vid in evals[app][s]:\n",
    "            try:\n",
    "                print(evals[app][s][vid][item])\n",
    "            except: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [(f'S{i}', f'vid{j}') for i in range(5) for j in range(4)]\n",
    "pairs = list(x for x in combinations_with_replacement(l, 2) if x[0] != x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car_report', 'king', 'tasty']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path(\"/tf/data/datasets/validation_set\")\n",
    "vid_ds = VideoDataset.from_path(path).label_from_paths()\n",
    "vid_ds.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdl_00_vid_threshold = 0.9\n",
    "mdl_00_frame_threshold = 0.9\n",
    "vw = 100\n",
    "\n",
    "M00 = SIFTExtractor(cv2.xfeatures2d.SIFT_create())\n",
    "fname = f'/tf/data/models/cookbook_M00_1000n_100vw.model'\n",
    "codebook_00 = pickle.load(open(fname, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_00 = approach(\n",
    "    vid_ds, M00, mdl_00_vid_threshold, sift_frame_sim,\n",
    "    mdl_00_frame_threshold, codebook_00, vw, 19, fps = 30, ftk = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_00_bovw_align = approach(\n",
    "    vid_ds, M00, mdl_00_vid_threshold, sift_frame_sim,\n",
    "    mdl_00_frame_threshold, codebook_00, vw, 19, fps = 30, ftk = 1,\n",
    "    align_sim = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_report σ Rank 2.277608394786075\n",
      "car_report μ Rank 2.25\n",
      "car_report Median Rank 1.5\n",
      "car_report mRR: 0.6937121212121212\n",
      "car_report mAP: 0.5326424678262913\n",
      "king σ Rank 4.363484845854286\n",
      "king μ Rank 3.4\n",
      "king Median Rank 1.0\n",
      "king mRR: 0.6980373303167421\n",
      "king mAP: 0.4601591918716531\n",
      "tasty σ Rank 0.7810249675906654\n",
      "tasty μ Rank 1.3\n",
      "tasty Median Rank 1.0\n",
      "tasty mRR: 0.9041666666666666\n",
      "tasty mAP: 0.8303373015873016\n"
     ]
    }
   ],
   "source": [
    "evals_00 = evaluate(results_00) # ftk = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3222222222222222\n",
      "0.29444444444444445\n",
      "0.7916666666666666\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.7916666666666666\n",
      "0.5555555555555555\n",
      "0.8666666666666667\n",
      "0.625\n",
      "0.7666666666666666\n",
      "0.8095238095238094\n",
      "0.9166666666666666\n",
      "0.8666666666666667\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-58d4912c0894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_eval_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tasty'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average_precision'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-ce4503456add>\u001b[0m in \u001b[0;36mget_eval_results\u001b[0;34m(evals, app, item)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_eval_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mvid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "get_eval_results(evals_00, 'tasty', 'average_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_01_vid_threshold = 0.9\n",
    "mdl_01_frame_threshold = 0.9\n",
    "model = SimCLRModel.load_from_checkpoint(checkpoint_path='/tf/data/models/simclr/checkpointepoch=98.ckpt').eval()\n",
    "M01 = SimCLRExtractor(model)\n",
    "\n",
    "fname = f'/tf/data/models/cookbook_M01_1000n_100vw.model'\n",
    "codebook_01 = pickle.load(open(fname, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7197b58b1be2410f9ac17766228622f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_report\n",
      "king\n",
      "tasty\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_01 = approach(\n",
    "    vid_ds, M01, mdl_01_vid_threshold, simclr_frame_sim,\n",
    "    mdl_01_frame_threshold, codebook_01, vw, 19, fps = 30, ftk = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3404184e424491b85a17c14e8cdfa04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_report\n",
      "king\n",
      "tasty\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157eadff93ca458d9bb73b4f4ba83d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy: 3.0 8\n",
      "Fuzzy: 3.0 6\n",
      "Fuzzy: 2.0 8\n",
      "Fuzzy: 3.0 8\n",
      "Fuzzy: 3.0 8\n",
      "Fuzzy: 3.0 8\n",
      "Fuzzy: 3.0 8\n",
      "Fuzzy: 3.0 8\n",
      "Fuzzy: 4.0 8\n",
      "Fuzzy: 3.0 8\n",
      "Fuzzy: 3.0 8\n",
      "Fuzzy: 3.0 8\n",
      "Fuzzy: 3.0 8\n",
      "Fuzzy: 3.0 8\n",
      "Fuzzy: 3.0 8\n",
      "Fuzzy: 3.0 8\n",
      "Fuzzy: 3.0 8\n",
      "Fuzzy: 3.0 8\n"
     ]
    }
   ],
   "source": [
    "results_01_bovw_align = approach(\n",
    "    vid_ds, M01, mdl_01_vid_threshold, sift_frame_sim,\n",
    "    mdl_01_frame_threshold, codebook_01, vw, 19, fps = 30, ftk = 1,\n",
    "    align_sim = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_report σ Rank 3.6318039594669758\n",
      "car_report μ Rank 2.9\n",
      "car_report Median Rank 1.0\n",
      "car_report mRR: 0.7559294871794873\n",
      "car_report mAP: 0.6176476198380222\n",
      "king σ Rank 0.6538348415311012\n",
      "king μ Rank 1.15\n",
      "king Median Rank 1.0\n",
      "king mRR: 0.9625\n",
      "king mAP: 0.8069936058093953\n",
      "tasty σ Rank 0.3\n",
      "tasty μ Rank 1.1\n",
      "tasty Median Rank 1.0\n",
      "tasty mRR: 0.95\n",
      "tasty mAP: 0.8740277777777777\n"
     ]
    }
   ],
   "source": [
    "evals_01 = evaluate(results_01) # ftk = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1280284043441938\n",
      "0.1153096416254311\n",
      "0.43977591036414565\n",
      "0.5254901960784314\n",
      "0.31746031746031744\n",
      "0.27777777777777773\n",
      "0.2896825396825397\n",
      "0.5166666666666667\n",
      "0.20664983164983164\n",
      "1.0\n",
      "0.7777777777777778\n",
      "0.5916666666666667\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.7222222222222222\n",
      "0.9166666666666666\n",
      "0.7222222222222222\n",
      "0.8055555555555555\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-c801d23fff74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_eval_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'car_report'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average_precision'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-ce4503456add>\u001b[0m in \u001b[0;36mget_eval_results\u001b[0;34m(evals, app, item)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_eval_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mvid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "get_eval_results(evals_01, 'car_report', 'average_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vw = 100\n",
    "\n",
    "M00 = SIFTExtractor(cv2.xfeatures2d.SIFT_create())\n",
    "fname = f'/tf/data/models/cookbook_M00_1000n_100vw.model'\n",
    "codebook_00 = pickle.load(open(fname, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = len(vid_0)\n",
    "n = len(vid_1)\n",
    "\n",
    "fuzzy_LCS(vid_0, vid_1, 10, 10, sift_frame_sim, M00, codebook_00, vw, 0.955, fps = 30, frames_to_keep = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimCLRModel.load_from_checkpoint(checkpoint_path='/tf/data/models/simclr/checkpointepoch=98.ckpt').eval()\n",
    "M01 = SimCLRExtractor(model)\n",
    "\n",
    "fname = f'/tf/data/models/cookbook_M01_1000n_100vw.model'\n",
    "codebook_01 = pickle.load(open(fname, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = len(vid_0)\n",
    "n = len(vid_1)\n",
    "\n",
    "fuzzy_LCS(vid_0, vid_1, 10, 10, simclr_frame_sim, M01, codebook_01, vw, 0.76, frames_to_keep = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From geeksforgeeks: https://www.geeksforgeeks.org/longest-common-substring-dp-29/\n",
    "def fuzzy_LCS(X, Y, m, n):\n",
    "    # Create a table to store lengths of \n",
    "    # longest common suffixes of substrings.  \n",
    "    # Note that LCSuff[i][j] contains the  \n",
    "    # length of longest common suffix of  \n",
    "    # X[0...i-1] and Y[0...j-1]. The first \n",
    "    # row and first column entries have no \n",
    "    # logical meaning, they are used only \n",
    "    # for simplicity of the program. \n",
    "      \n",
    "    # LCSuff is the table with zero  \n",
    "    # value initially in each cell \n",
    "    LCSuff = [[0 for k in range(n+1)] for l in range(m+1)] \n",
    "      \n",
    "    # To store the length of  \n",
    "    # longest common substring \n",
    "    result = 0 \n",
    "  \n",
    "    # Following steps to build \n",
    "    # LCSuff[m+1][n+1] in bottom up fashion \n",
    "    for i in range(m + 1): \n",
    "        for j in range(n + 1): \n",
    "            if (i == 0 or j == 0): \n",
    "                LCSuff[i][j] = 0\n",
    "            elif (X[i-1] == Y[j-1]): \n",
    "                LCSuff[i][j] = LCSuff[i-1][j-1] + 1\n",
    "                result = max(result, LCSuff[i][j]) \n",
    "            else: \n",
    "                LCSuff[i][j] = 0\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 'aaaaaaaaaaaaaa'\n",
    "Y = 'aaaaaaaaaaaaaa'\n",
    "  \n",
    "m = len(X) \n",
    "n = len(Y) \n",
    "  \n",
    "print('Length of Longest Common Substring is', \n",
    "                      fuzzy_LCS(X, Y, m, n)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "\n",
    "> This module contains all the code for running our experiments for Tango. To reproduce our results, please run each of the cells in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import csv\n",
    "import cv2\n",
    "import fnmatch\n",
    "import json\n",
    "import ntpath\n",
    "import os\n",
    "import pytesseract\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def write_json_line_by_line(data, file_path):\n",
    "    with open(file_path, 'w') as dest_file:\n",
    "        for record in data:\n",
    "            print(json.dumps(record), file=dest_file)\n",
    "\n",
    "\n",
    "def read_csv_to_dic_list(file_path):\n",
    "    data = []\n",
    "    with open(file_path) as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file, delimiter=';')\n",
    "        for item in csv_reader:\n",
    "            data.append(item)\n",
    "    return data\n",
    "\n",
    "\n",
    "def read_json(file_path):\n",
    "    with open(file_path) as file:\n",
    "        return json.load(file)\n",
    "\n",
    "\n",
    "def read_json_line_by_line(file_path):\n",
    "    data = []\n",
    "    with open(file_path) as sett_file:\n",
    "        for item in map(json.loads, sett_file):\n",
    "            data.append(item)\n",
    "    return data\n",
    "\n",
    "\n",
    "def find_file(pattern, path):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            if fnmatch.fnmatch(name, pattern):\n",
    "                if 'fix' not in name:\n",
    "                    result.append(os.path.join(root, name))\n",
    "    return result\n",
    "\n",
    "\n",
    "def write_csv_from_json_list(data, output_path):\n",
    "    pd.read_json(json.dumps(data)).to_csv(output_path, index=False, sep=\";\")\n",
    "\n",
    "\n",
    "def group_dict(data, lambda_expr):\n",
    "    result = {}\n",
    "    data.sort(key=lambda_expr)\n",
    "    for k, v in groupby(data, key=lambda_expr):\n",
    "        result[k] = list(v)\n",
    "    return result\n",
    "\n",
    "\n",
    "def load_settings(path):\n",
    "    settings_files = find_file(\"*.json\", path)\n",
    "\n",
    "    all_settings = {}\n",
    "    for file_path in settings_files:\n",
    "        setting_name = ntpath.basename(file_path).split(\".\")[0]\n",
    "        all_settings[setting_name] = []\n",
    "        with open(file_path) as sett_file:\n",
    "            for retrieval_run in map(json.loads, sett_file):\n",
    "                all_settings[setting_name].append(retrieval_run)\n",
    "\n",
    "    return all_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# noise removal\n",
    "def remove_noise(image):\n",
    "    return cv2.medianBlur(image, 5)\n",
    "\n",
    "\n",
    "# thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "def thresholding_med(image):\n",
    "    return cv2.threshold(cv2.medianBlur(image, 3), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations=1)\n",
    "\n",
    "\n",
    "# erosion\n",
    "def erode(image):\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "\n",
    "# opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "\n",
    "# canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n",
    "\n",
    "# skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "\n",
    "# template matching\n",
    "def match_template(image, template):\n",
    "    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def extract_text(img):\n",
    "    custom_config = r'--oem 3 --psm 3'\n",
    "    return pytesseract.image_to_string(img, config=custom_config)\n",
    "\n",
    "\n",
    "def preprocess_img(image):\n",
    "    prep_img = get_grayscale(image)\n",
    "    prep_img = opening(prep_img)\n",
    "    prep_img = thresholding_med(prep_img)\n",
    "    return prep_img\n",
    "\n",
    "\n",
    "def extract_frames(video_path, out_path, fps):\n",
    "    ffmpeg_command = f'ffmpeg -i {video_path} -vf \"fps={fps}\" {out_path}/%04d.jpeg'\n",
    "    os.system(ffmpeg_command)\n",
    "\n",
    "\n",
    "def process_frame(frame):\n",
    "    image_frame = cv2.imread(frame)\n",
    "    prep_image = preprocess_img(image_frame)\n",
    "    text = extract_text(prep_image)\n",
    "\n",
    "    frame_name = ntpath.basename(frame).split(\".\")[0]\n",
    "    record = {\"f\": frame_name, \"txt\": text}\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

---

title: Title

keywords: fastai
sidebar: home_sidebar

summary: "summary"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/[Scratch 2] Tango SimCLR.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span> pip install numpy
<span class="o">!</span> pip install --pre -U torch torchvision -f https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.16.0)
Looking in links: https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html
Collecting torch
  Using cached https://download.pytorch.org/whl/nightly/cu102/torch-1.7.0.dev20200702-cp36-cp36m-linux_x86_64.whl (893.2 MB)
Collecting torchvision
  Using cached https://download.pytorch.org/whl/nightly/cu102/torchvision-0.8.0.dev20200701-cp36-cp36m-linux_x86_64.whl (5.9 MB)
Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.18.2)
Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.0)
Requirement already satisfied, skipping upgrade: pillow&gt;=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.1.0)
<span class="ansi-red-fg">ERROR: torchvision 0.8.0.dev20200701 has requirement torch==1.7.0.dev20200701, but you&#39;ll have torch 1.7.0.dev20200702 which is incompatible.</span>
Installing collected packages: torch, torchvision
  Attempting uninstall: torch
    Found existing installation: torch 1.3.1
    Uninstalling torch-1.3.1:
      Successfully uninstalled torch-1.3.1
  Attempting uninstall: torchvision
    Found existing installation: torchvision 0.4.2
    Uninstalling torchvision-0.4.2:
      Successfully uninstalled torchvision-0.4.2
Successfully installed torch-1.7.0.dev20200702 torchvision-0.8.0.dev20200701
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span> pip install pytorch-lightning
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting pytorch-lightning
  Downloading pytorch_lightning-0.8.4-py3-none-any.whl (304 kB)
     |████████████████████████████████| 304 kB 4.5 MB/s eta 0:00:01
Collecting PyYAML&gt;=5.1
  Downloading PyYAML-5.3.1.tar.gz (269 kB)
     |████████████████████████████████| 269 kB 13.9 MB/s eta 0:00:01
Collecting tqdm&gt;=4.41.0
  Downloading tqdm-4.47.0-py2.py3-none-any.whl (66 kB)
     |████████████████████████████████| 66 kB 12.0 MB/s eta 0:00:01
Requirement already satisfied: torch&gt;=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.7.0.dev20200702)
Requirement already satisfied: tensorboard&gt;=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (2.2.2)
Requirement already satisfied: numpy&gt;=1.15 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.18.5)
Requirement already satisfied: future&gt;=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (0.18.2)
Requirement already satisfied: requests&lt;3,&gt;=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard&gt;=1.14-&gt;pytorch-lightning) (2.24.0)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard&gt;=1.14-&gt;pytorch-lightning) (1.6.0.post3)
Requirement already satisfied: grpcio&gt;=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard&gt;=1.14-&gt;pytorch-lightning) (1.30.0)
Requirement already satisfied: protobuf&gt;=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard&gt;=1.14-&gt;pytorch-lightning) (3.12.2)
Requirement already satisfied: google-auth&lt;2,&gt;=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard&gt;=1.14-&gt;pytorch-lightning) (1.18.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard&gt;=1.14-&gt;pytorch-lightning) (3.2.2)
Requirement already satisfied: setuptools&gt;=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard&gt;=1.14-&gt;pytorch-lightning) (47.3.1)
Requirement already satisfied: six&gt;=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard&gt;=1.14-&gt;pytorch-lightning) (1.15.0)
Requirement already satisfied: werkzeug&gt;=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard&gt;=1.14-&gt;pytorch-lightning) (1.0.1)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard&gt;=1.14-&gt;pytorch-lightning) (0.4.1)
Requirement already satisfied: absl-py&gt;=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard&gt;=1.14-&gt;pytorch-lightning) (0.9.0)
Requirement already satisfied: wheel&gt;=0.26; python_version &gt;= &#34;3&#34; in /usr/lib/python3/dist-packages (from tensorboard&gt;=1.14-&gt;pytorch-lightning) (0.30.0)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/lib/python3/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&gt;=1.14-&gt;pytorch-lightning) (2.6)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&gt;=1.14-&gt;pytorch-lightning) (3.0.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&gt;=1.14-&gt;pytorch-lightning) (2020.6.20)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&gt;=1.14-&gt;pytorch-lightning) (1.25.9)
Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&gt;=1.14-&gt;pytorch-lightning) (4.1.0)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4; python_version &gt;= &#34;3&#34; in /usr/local/lib/python3.6/dist-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&gt;=1.14-&gt;pytorch-lightning) (4.6)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&gt;=1.14-&gt;pytorch-lightning) (0.2.8)
Requirement already satisfied: importlib-metadata; python_version &lt; &#34;3.8&#34; in /usr/local/lib/python3.6/dist-packages (from markdown&gt;=2.6.8-&gt;tensorboard&gt;=1.14-&gt;pytorch-lightning) (1.7.0)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&gt;=1.14-&gt;pytorch-lightning) (1.3.0)
Requirement already satisfied: pyasn1&gt;=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa&lt;5,&gt;=3.1.4; python_version &gt;= &#34;3&#34;-&gt;google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&gt;=1.14-&gt;pytorch-lightning) (0.4.8)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version &lt; &#34;3.8&#34;-&gt;markdown&gt;=2.6.8-&gt;tensorboard&gt;=1.14-&gt;pytorch-lightning) (3.1.0)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&gt;=1.14-&gt;pytorch-lightning) (3.1.0)
Building wheels for collected packages: PyYAML
  Building wheel for PyYAML (setup.py) ... done
  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=45919 sha256=6420b08d2a2f9d7f97a06d8a95662cd3c32468e455f2c683d62f723e12f5f9ef
  Stored in directory: /root/.cache/pip/wheels/e5/9d/ad/2ee53cf262cba1ffd8afe1487eef788ea3f260b7e6232a80fc
Successfully built PyYAML
Installing collected packages: PyYAML, tqdm, pytorch-lightning
Successfully installed PyYAML-5.3.1 pytorch-lightning-0.8.4 tqdm-4.47.0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="k">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="k">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="k">import</span> <span class="n">transforms</span>

<span class="kn">from</span> <span class="nn">pytorch_lightning</span> <span class="k">import</span> <span class="n">Trainer</span>

<span class="k">class</span> <span class="nc">SimCLRDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize a wrapper of a generic image classification dataset for SimCLR training.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset (torch.utils.data.Dataset): an image PyTorch dataset - when iterating over it</span>
<span class="sd">                it should return something of the form (image) or (image, label).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">dataset_item</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">dataset_item</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">tuple</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">dataset_item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">dataset_item</span>
        <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">image</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">mixup</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="k">if</span> <span class="n">alpha</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">lam</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
            <span class="n">lam</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                <span class="p">[</span><span class="n">lam</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">lam</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]],</span> <span class="mi">1</span>
            <span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
            <span class="n">lam</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">lam</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="n">lam</span> <span class="o">=</span> <span class="n">lam</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lam</span> <span class="o">=</span> <span class="mf">1.</span>
        <span class="c1"># This is SimCLR specific - we want to use the same mixing for the augmented pairs</span>
        <span class="n">lam</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">lam</span><span class="p">,</span> <span class="n">lam</span><span class="p">])</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="c1"># This is SimCLR specific - we want to use the same permutation on the augmented pairs</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">index</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">+</span> <span class="n">index</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="n">mixed_x</span> <span class="o">=</span> <span class="n">lam</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">lam</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:]</span>

        <span class="k">return</span> <span class="n">mixed_x</span><span class="p">,</span> <span class="n">lam</span>


<span class="k">def</span> <span class="nf">imagenet_normalize_transform</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">get_train_transforms</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span> <span class="n">color_jitter_prob</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">grayscale_prob</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
    <span class="n">color_jitter</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ColorJitter</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomApply</span><span class="p">([</span><span class="n">color_jitter</span><span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="n">color_jitter_prob</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomGrayscale</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">grayscale_prob</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">imagenet_normalize_transform</span><span class="p">()</span>
    <span class="p">])</span>


<span class="k">def</span> <span class="nf">get_val_transforms</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">224</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">imagenet_normalize_transform</span><span class="p">()</span>
    <span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>


<span class="k">class</span> <span class="nc">NTXEntCriterion</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Normalized, temperature-scaled cross-entropy criterion, as suggested in the SimCLR paper.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        temperature (float, optional): temperature to scale the confidences. Defaults to 0.5.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">)</span>
    <span class="n">similarity</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CosineSimilarity</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NTXEntCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">mask_correlated_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Masks examples in a batch and it&#39;s augmented pair for computing the valid summands for</span>
<span class="sd">            the criterion.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_size (int): batch size of the individual batch (not including it&#39;s augmented pair)</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: a mask (tensor of 0s and 1s), where 1s indicates a pair of examples in a</span>
<span class="sd">                batch that will contribute to the overall batch loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">batch_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">fill_diagonal_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">mask</span><span class="p">[</span><span class="n">batch_size</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">mask</span>

    <span class="k">def</span> <span class="nf">compute_similarities</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_i</span><span class="p">,</span> <span class="n">z_j</span><span class="p">,</span> <span class="n">temperature</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes the similarities between two projections `z_i` and `z_j`, scaling based on</span>
<span class="sd">            `temperature`.</span>

<span class="sd">        Args:</span>
<span class="sd">            z_i (torch.Tensor): projection of a batch</span>
<span class="sd">            z_j (torch.Tensor): projection of the augmented pair for the batch</span>
<span class="sd">            temperature (float): temperature to scale the similarity by</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: tensor of similarities for the positive and negative pairs</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">z_i</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_correlated_samples</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="n">p1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">z_i</span><span class="p">,</span> <span class="n">z_j</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">sim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="n">p1</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">p1</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="o">/</span> <span class="n">temperature</span>

        <span class="n">sim_i_j</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">sim</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">sim_j_i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">sim</span><span class="p">,</span> <span class="o">-</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="n">positive_samples</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">sim_i_j</span><span class="p">,</span> <span class="n">sim_j_i</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="n">batch_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">negative_samples</span> <span class="o">=</span> <span class="n">sim</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">positive_samples</span><span class="p">,</span> <span class="n">negative_samples</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes the loss for a batch and its augmented pair.</span>

<span class="sd">        Args:</span>
<span class="sd">            z (torch.Tensor): tensor of a batch and it&#39;s augmented pair, concatenated</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: loss for the given batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">double_batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">double_batch_size</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">z_i</span><span class="p">,</span> <span class="n">z_j</span> <span class="o">=</span> <span class="n">z</span><span class="p">[:</span><span class="n">double_batch_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">],</span> <span class="n">z</span><span class="p">[</span><span class="n">double_batch_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">:]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_correlated_samples</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_similarities</span><span class="p">(</span><span class="n">z_i</span><span class="p">,</span> <span class="n">z_j</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="n">logits</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">/=</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">return</span> <span class="n">loss</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_lightning.core.lightning</span> <span class="k">import</span> <span class="n">LightningModule</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="k">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">torchvision</span>

<span class="k">class</span> <span class="nc">SimCLRModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;SimCLR training network for a generic torchvision model (restricted to `allowed_models`). &quot;&quot;&quot;</span>

    <span class="n">allowed_models</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;resnet18&#39;</span><span class="p">,</span> <span class="s1">&#39;resnet34&#39;</span><span class="p">,</span> <span class="s1">&#39;resnet50&#39;</span><span class="p">,</span> <span class="s1">&#39;resnet101&#39;</span><span class="p">,</span> <span class="s1">&#39;resnet152&#39;</span><span class="p">]</span>
    <span class="n">allowed_datasets</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CIFAR10&#39;</span><span class="p">,</span> <span class="s1">&#39;CIFAR100&#39;</span><span class="p">,</span> <span class="s1">&#39;STL10&#39;</span><span class="p">,</span> <span class="s1">&#39;SVHN&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;resnet18&#39;</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">projection_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span> <span class="n">save_hparams</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)(</span><span class="n">pretrained</span><span class="o">=</span><span class="n">pretrained</span><span class="p">)</span><span class="o">.</span><span class="n">children</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">projection_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">NTXEntCriterion</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">=</span> <span class="n">image_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="c1">#         print(&quot;Forwarding&quot;)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_head</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
<span class="c1">#         print(&quot;Training step&quot;)</span>
        <span class="n">projections</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">projections</span><span class="p">)</span>
        <span class="n">tensorboard_logs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;log&#39;</span><span class="p">:</span> <span class="n">tensorboard_logs</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">training_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
<span class="c1">#         print(&quot;Finished Epoch&quot;)</span>
        <span class="n">loss_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">loss_mean</span><span class="p">}</span>

<span class="c1">#     def validation_step(self, batch, batch_idx):</span>
<span class="c1"># #         print(&quot;Validation step&quot;)</span>
<span class="c1">#         projections = self(batch)</span>
<span class="c1">#         loss = self.loss(projections)</span>
<span class="c1">#         tensorboard_logs = {&#39;val_loss&#39;: loss}</span>
<span class="c1">#         return {&#39;loss&#39;: loss, &#39;log&#39;: tensorboard_logs}</span>

<span class="c1">#     def validation_epoch_end(self, outputs):</span>
<span class="c1"># #         print(&quot;Finished Epoch&quot;)</span>
<span class="c1">#         val_loss_mean = torch.stack([x[&#39;loss&#39;] for x in outputs]).mean()</span>
<span class="c1">#         return {&#39;val_loss&#39;: val_loss_mean}</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span>
            <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.00001</span><span class="p">},</span>
            <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_head</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">}</span>
        <span class="p">])</span>

    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="c1">#         print(&quot;Getting Data&quot;)</span>
        <span class="n">train_transforms</span><span class="p">,</span> <span class="n">val_transforms</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">get_train_transforms</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">),</span>
            <span class="n">get_val_transforms</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span>
            <span class="s1">&#39;/tf/data/combined&#39;</span><span class="p">,</span> <span class="n">transform</span> <span class="o">=</span> <span class="n">train_transforms</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">SimCLRDataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
<span class="c1">#         val_dataset = torchvision.datasets.ImageFolder(</span>
<span class="c1">#             &#39;/tf/data/combined&#39;, transform = val_transforms)</span>
<span class="c1">#         self.val_dataset = SimCLRDataset(val_dataset)</span>
<span class="c1">#         print(&quot;Finished getting data&quot;)</span>

    <span class="k">def</span> <span class="nf">collate_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
<span class="c1">#         print(&quot;Collating data&quot;)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])])</span>

    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="c1">#         print(&quot;Grabbing dataloader&quot;)</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">collate_fn</span>
        <span class="p">)</span>

<span class="c1">#     def val_dataloader(self):</span>
<span class="c1"># #         print(&quot;Grabbing dataloader&quot;)</span>
<span class="c1">#         return DataLoader(</span>
<span class="c1">#             self.val_dataset, batch_size=self.batch_size, num_workers=64, shuffle=False,</span>
<span class="c1">#             collate_fn=self.collate_fn</span>
<span class="c1">#         )</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">SimCLRModel</span><span class="p">(</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;resnet50&#39;</span><span class="p">,</span>
    <span class="n">pretrained</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1792</span><span class="p">,</span>
    <span class="n">image_size</span> <span class="o">=</span> <span class="mi">224</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">SimCLRModel</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="o">=</span><span class="s1">&#39;/tf/data/models/simclr/checkpointepoch=98.ckpt&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;/tf/data/models/simclr/simclr-epoch98.pth&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_lightning.callbacks</span> <span class="k">import</span> <span class="n">ModelCheckpoint</span>


<span class="n">checkpoint_callback</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span>
    <span class="n">filepath</span> <span class="o">=</span> <span class="s1">&#39;/tf/data/models/simclr/&#39;</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;checkpoint&quot;</span><span class="p">,</span>
    <span class="n">monitor</span> <span class="o">=</span> <span class="s2">&quot;val_loss&quot;</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="n">save_top_k</span> <span class="o">=</span> <span class="mi">3</span>
<span class="p">)</span>

<span class="n">train_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
<span class="c1">#     accumulate_grad_batches = 1, # hparams.gradient_accumulation_steps,</span>
    <span class="n">gpus</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="c1"># hparams.num_train_epochs,</span>
    <span class="n">early_stop_callback</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="c1">#     gradient_clip_val = 3, # hparams.max_grad_norm,</span>
<span class="c1">#     checkpoint_callback = checkpoint_callback,</span>
    <span class="n">num_nodes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">distributed_backend</span> <span class="o">=</span> <span class="s1">&#39;ddp&#39;</span><span class="p">,</span>
<span class="c1">#     precision = 16</span>
<span class="c1">#     num_workers = 0</span>
<span class="c1">#     callbacks=[LoggingCallback()],</span>
<span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="o">**</span><span class="n">train_params</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: Checkpoint directory /tf/data/models/simclr/ exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!
  warnings.warn(*args, **kwargs)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-2-e2fa7c6642d9&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">     22</span> )
<span class="ansi-green-intense-fg ansi-bold">     23</span> 
<span class="ansi-green-fg">---&gt; 24</span><span class="ansi-red-fg"> </span>trainer <span class="ansi-blue-fg">=</span> Trainer<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">**</span>train_params<span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">NameError</span>: name &#39;Trainer&#39; is not defined</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> tensorboard
<span class="o">%</span><span class="k">tensorboard</span> --bind_all --logdir lightning_logs/
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

      <iframe id="tensorboard-frame-31a2232f4f6903b0" width="100%" height="800" frameborder="0">
      </iframe>
      <script>
        (function() {
          const frame = document.getElementById("tensorboard-frame-31a2232f4f6903b0");
          const url = new URL("/", window.location);
          url.port = 6006;
          frame.src = url;
        })();
      </script>
  
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># trainer = Trainer.from_argparse_args(args)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>
 

